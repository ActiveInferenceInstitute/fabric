**Refined Text:**

Hello and welcome. This is Actin Guest Stream number 87.2, recorded on September 10th, 2024. We will continue our exploration of the Cogar Ecosystem series with John Bo. Thank you again, John; please proceed, and we look forward to comments and questions from the audience.

Thank you, Daniel. My name is John Bo, and I am a research fellow at the Active Inference Institute. I have two new papers posted as preprints, which are the focus of these live streams. The first stream, held on September 5th, discussed the first paper. I encourage listeners to check it out; the links are available in the PDF. Today, we will discuss the second paper, titled "Cogar Ecosystem: Preliminary Thoughts on a Story Graph Meaning Representation."

The following slides will provide brief recaps of our previous discussions. The Cogar project is new, extensive, and relatively complex. To set the stage for today’s talk, it may be helpful to quickly review some of the main components of the Cogar system. "Cogar" stands for cognitive narrative. The Cogar system is still a developing concept; it is being actively created. It is envisioned as an open-source online ecosystem of tools and services that facilitates group cognition, particularly for large groups, focusing on deliberation, strategizing, and collective problem-solving.

The Cogar system assists users in "telling their story." In this context, I use the terms "story" and "narrative" in the paper and during this talk, not to refer to fables, but rather to signify a belief model of a user. The premise is that, concerning a specific problem or situation of interest, a group engages in an online discussion, where users externalize their belief models. In this narrative, they describe the situation or problem, explain what occurred, discuss why it happened, predict what might happen next, and address questions such as who is affected, who was involved, what it means, what actions should be taken, and what can be learned. Thus, a story serves as a model—an externalization of beliefs that reflects how a user perceives the world and its functioning.

Stories can be rich, meaning they may be long, complex, nuanced, informative, conditional, and dynamic. A typical story might span several pages of text, or it could be as brief as a paragraph, depending on what the user wishes to convey. This richness distinguishes Cogar from other online services aimed at collaborative decision-making, which often rely on multiple-choice formats or brief responses. In contrast, the stories within Cogar can be far more elaborate.

The backend computational system supports users in constructing their stories, assesses the quality of these narratives—such as whether they are on-topic and comprehensible—and assists the group in digesting and making sense of multiple submissions. This system can potentially handle a vast number of participants, ranging from thousands to millions. Additionally, it can infer responses to user-generated queries. For instance, if I have a question regarding a specific narrative—such as whether unemployment is predicted to decline—I can pose a query to the system, which may also generate its own questions to clarify the user’s input. However, it is crucial to note that the system does not predict the future or assess the realism or accuracy of a story; that responsibility lies with the group collecting the narratives.

The implications of these points mean that the backend system does not require its own model of reality; it merely needs to facilitate the communication of stories and help users articulate and share their belief systems. If the objective of the Cogar system is to enable group cognition, an important question arises: What constitutes cognition? In this project, I examine cognition through the lens of active inference, a normative Bayesian description of cognitive processes.

In active inference, an agent possesses an internal probabilistic model of how the world operates. This model is externalized through stories. Cognition can be simplified into a four-part cyclic process: predict, act, sense, and learn. I emphasize the word "act" here, as it is often overlooked in discussions of cognition. For example, while learning to play football, I might predict that if I jump high and raise my arms, I will catch a high pass. I then act on that prediction, sense the outcome, and learn from any mistakes. Over time, this iterative process improves my ability to catch the ball.

Active inference is normative, providing a description of functional cognition. In contrast, dysfunctional cognition fails to ensure optimal resolution of uncertainty regarding preferred outcomes. If uncertainty does not decrease about desired outcomes, it indicates potential cognitive dysfunction.

Next, I will clarify what Cogar is. I conceptualize a group as a cognitive organism, requiring the ability to react within its environment, following the four-step process of sensing, acting, learning, and predicting. Cognitive architecture integrates information and coordinates action. For individuals, cognitive architecture comprises biological systems, the central nervous system, and tools such as computers. For groups, cognitive architecture may include rules, methods, institutions, and sensors—such as environmental sensors for a nation. In a previous series of papers, I explored a society's core systems, including governance, economic, and legal systems, as part of its cognitive architecture. The Cogar project is closely related to that initial exploration.

Cogar serves as a component of the cognitive architecture for groups, aiming to facilitate functional cognition. A story, in this context, represents a dynamic externalized representation of a user’s internal belief model about how the world works.

Underpinning this system is the concept of the story graph. Although I refer to stories and narratives, I do not mean textual information; rather, users communicate and share their stories in a specialized meaning representation I call a story graph. Story graphs are the core innovation of the Cogar system, enabling it to function effectively. This diagram illustrates how story graphs are constructed. A user may input short text passages—sentences or metadata, such as tables or graphs—which the system translates into story graph fragments, merging them into a growing story graph. Once constructed, various actions can occur, such as translating the story graph into natural language or other analytical models.

The purpose of the story graph is to present a story in a format that is less ambiguous than natural language, which can often be unclear. This representation should be understandable by both humans and computers. Users should be able to verify that the system has accurately interpreted their narratives, providing a structured basis for inference and analysis. Furthermore, it serves as an interlingua—a natural language-independent representation suitable for translation into other languages and models.

Now, we can delve into today’s discussion on the Cogar meaning representation, which must be fit for purpose. The task at hand is to design a meaning representation capable of performing various functions. Before we proceed, I will highlight several well-known meaning representations used in research, particularly within the context of natural language inference (NLI), which falls under the broader category of natural language processing (NLP). NLI is often considered one of the most challenging tasks within NLP, as it requires the system or model to understand the meaning of text.

Typically, NLI begins with the selection of a specific text—often a single sentence or a small number of sentences—extracted from a database with well-understood meanings. This text is sent to a natural language processing system for parsing and disambiguation, after which the resulting meaning representation, such as Abstract Meaning Representation (AMR), is utilized within an inference method. However, the Cogar system operates differently; the steps involved in creating the story occur almost simultaneously and interactively, as users contribute text to construct narratives.

In NLI studies, the text is fixed, and the model is evaluated based on its understanding of that specific text. Conversely, in Cogar, if the system does not comprehend a user’s input, it can request clarification or feedback, allowing the user to adjust their text. This interaction reduces ambiguity and enhances the quality of the submitted stories. The backend system can then convert the text into story graph fragments and facilitate collaborative decision-making through iterative rounds of sharing and editing stories. This dynamic process enables users to improve their narratives based on feedback from others.

The literature has proposed numerous meaning representations, and I will present a table that outlines a selection of them. In the current discourse, we will focus on a few specific representations, including Discourse Representation Theory (DRT), Type Theory with Records (TTR), and Disco Circ, which, while not a formal meaning representation, is closely related.

A significant consideration in our exploration is the use of graphical meaning representations. Graph-based representations are advantageous because they allow computers to process information efficiently. The importance of a backend computational system in assessing stories is underscored by the need for a method to digest complex information submitted by large groups. For instance, if a hundred thousand people submit lengthy, nuanced stories, human capability to digest such information is limited. Thus, a graph-based meaning representation can help the system understand and analyze submissions more effectively.

In conclusion, the Cogar project seeks to create a sophisticated meaning representation that accommodates the complexity of group cognition while remaining accessible and functional. The intersection of cognitive science, linguistics, and computational modeling provides a rich landscape for future exploration and research.

**List of Changes Made:**

1. Improved grammatical structure for clarity and coherence.
2. Replaced informal phrases with formal academic language.
3. Removed trivial statements and redundant phrases to enhance clarity.
4. Organized the text into clear sections, improving the overall flow.
5. Clarified complex concepts and terminology for better comprehension.
6. Removed unnecessary repetition of phrases and ideas.
7. Enhanced the precision of language, particularly in describing the Cogar system and its components.
8. Ensured that all references to theories and models were clearly defined and contextualized.
9. Streamlined the explanation of processes to avoid wordiness and enhance readability.
10. Maintained the original meaning and intent throughout the refinement process.
