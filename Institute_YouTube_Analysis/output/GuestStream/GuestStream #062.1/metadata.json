{
  "title": "ActInf GuestStream 062.1 ~ Michael Carl, \"Deep temporal Models of the Translation Process\"",
  "upload_date": "20231031",
  "duration": 5310,
  "view_count": 290,
  "like_count": 16,
  "channel": "Active Inference Institute",
  "description": "Michael Carl\n\"Deep temporal Models of the Translation Process\"\nhttps://scholar.google.com/citations?user=Ubt1EuUAAAAJ&hl=en\n\nAbstract: \nTranslation Process Research (TPR) investigates how humans produce translations from one language into another. Several methods have been used to gather evidence for the assumed underlying translation processes, including think-aloud, (retrospective) interviews, questionnaires, screen recording, brain image technologies (EEG, fMRI), etc. In our research, we use keyloggers and eyetrackers to collect behavioral data during the translation sessions. The two data streams are synchronized to establish correspondences between the sensory input (reading) and translational action (typing) and analyzed to arrive -- among other things -- at a better understanding of the relations between translation effort and effects, which heavily depend on the translator's expertise, text difficulty, expected translation quality, etc.\nNumerous models of the translating mind have been suggested, some of which suggest that multiple, more or less automatized and/or conscious translation processes complement each other during translation production. In this talk I suggest the Free Energy Principle (FEP) and Active Inference (AIF) as a novel framework for analyzing, specifying and modelling deep embedded translation processes and for simulating their interaction within the POMDP framework. I exemplify how translation-behavioral data (keystrokes and gaze data) elicit traces of a deep temporal architecture, in which human translation production is modelled in several temporally embedded and interacting processes that unfold on different timelines. Following FEP/AIF, the deep temporal architecture allows translators to arrive at a steady state of fluent translation production by minimizing the discrepancy between the translator's internal states and the (textual) states in the external translation environment.\n\n\nActive Inference Institute information: \nWebsite: https://activeinference.org/ \nTwitter: https://twitter.com/InferenceActive \nDiscord: https://discord.gg/8VNKNp4jtx \nYouTube: https://www.youtube.com/c/ActiveInference/ \nActive Inference Livestreams: https://coda.io/@active-inference-institute/livestreams",
  "is_live": false,
  "live_status": "was_live"
}