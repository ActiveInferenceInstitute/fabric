[Music] all right hello and welcome to active inference model stream number 13.1 it's August 23rd 2024 we're here with two of the authors of the paper synthesizing the born rule with reinforcement learning so thank you both for joining for this presentation and discussion to you Jo for the presentation great thanks for inviting me Daniel um and yeah it's really fun to learn about the the AC of inference Community um and to speak to you guys so I think there'll be as many questions from us to you uh as there will be from you guys to us um so I'm not going to take up too much time I hope with my slides um I wanted to just give a kind of high level overview of this article which hopefully um many of you have already had time to look over but I'll give you a high level overview and um that shouldn't take more than about 30 minutes I guess and after that we'll have plenty of time for discussion um there will be many points where you might feel that you want more information uh more more technical details but since I couldn't really predict which points might strike you as the most interesting I'll leave it to you to ask at the end and uh as necessary I might um be able to pull up the article and point the relevant Parts yeah uh let's dive into it oh and and one last thing you you might hear some background noises of either drilling or a baby screaming that's just uh because I'm at home at the moment and uh it's part of the domestic atmosphere okay let's go so this is um a very busy slide sorry for that but we do have a lot of people involved in this from many different institutions I'll I'll put this slide also at the end of the talk um in case you're curious but it's it's important to mention um we you we've got five people based at the uh Institute of physics uh in lab Q Rio Rio de Janeiro and that that's where I'm currently based although before this I was was uh where you know during the time that this paper was mostly written I was at the University of Massachusetts Boston together uh with um two other co-authors on this paper are from there as well and we're all part of the cubism group uh run by Chris fuks so I'll I'll speak a little bit about cubism um which is an interpretation of quantum theory based on subjective basion decision Theory a bit of mouthful but if you're curious about that we can talk about it more at the end uh and John has since gone on to um uh the University of New Mexico and the the lead author of this work is Rodrigo Pio who was a PhD student at the time of this work and he's now at the Technology Innovation Institute in Abu [Music] Dhabi so this is another paper that was published um some years ago now just during the pandemic or towards the end of the pandemic um and this was by us at the cubism group so you can see John and I are there uh Chris fuks is there um this was a purely theoretical paper but it contains the seeds for for the article that I'm going to talk about so I'm going to just take a little diversion to explain what we did in this paper as a a motivation for the article that I'll talk about here's a little exop from from the abstract the the title of the paper is born's Rule as a Quantum extension of basion coherence and explaining that a little bit uh from the abstract the subjective vasion interpretation of quantum mechanics that we calling cubism asserts that the born rule rule is a normative rule in analogy to Dutch book coherence I'll explain what born Rule and and Dutch book coherence are don't worry uh but with the addition of one or more empirical assumptions characterizing the particularities of the physical world so the idea is that we're taking this rule called the born rule from quantum physics and we're saying that you can understand that rule as coming from decision Theory this prision Theory plus certain empirical assumptions okay so let let me explain what what that means bit of terminology what is this interpretation the subje evasion interpretation of quantum theory well there's a lot I could say about it but for for the purposes of this paper decision theory in other words the theory of agents who are uh trying their best to make good decisions in the world and they use probability theory in order to do that and quantum theory takes into account certain empirical facts things that we've learned from experiments and uh gives us an upgrade to our decision Theory and that's what we call quantum mechanics according to [Music] cubism and when I talk about bn's rule you might have come across it in what I'm calling the Legacy form it's the rule that tells you when you have some Quantum State and you do a measurement on it which traditionally is an observable that has some set of igen States uh labeled with I've just labeled them abstractly with an index J I'm assuming a discrete Spectrum here uh then to find out the probability for getting some outcome J uh you you just have to uh take the overlap of the quantum state with the relevant igen projector and you take the modulus squared of that to give you a positive real number and that's the probability but nowadays uh We've generalized the rule so from uh the the literature on open systems and information Theory uh we have accommodated more General measurements so you don't just have to measure observables which are uh which kind of project you into an igen basis uh where each projector is orthogonal to the other ones uh you have these things called um positive operator value measures which is a horrible name we just call them povms and everyone even forgets what they stand for um but you can basically think about them as uh a general generalization of of um observables they're the most General thing the general most General kind of measurement you could possibly do in quantum theory so that's what that D subscript J stands for uh it's it's an element corresponding to outcome J of the most General Quantum measurement and then in that case the quantum state is represented by a density Matrix which is that little Greek letter row under the trace and if you take the trace of the state with the povm element DJ then that will give you the probability for the outcome J in that Quantum State row um I hope that's familiar to to at least some people watching this but if not feel free to quiz us on it it's not super important to the rest of the talk though the important thing is bn's rule is is a you can think of it like um a piece of the Machinery of quantum mechanics that takes your Quantum State and measurement and as input and it outputs the probability that you should assign uh for for each outcome so it's a very important piece of the quantum formalism and what we found in this old in this paper which is the motivation for all of this is the following imagine that you have a perfectly rational decision making agent okay per perfectly rational agents don't exist in reality but they're they're useful to contemplate in the abstract uh and by perfectly rational I I just mean that uh it it respects the the basic laws of probability Theory so it it assigns probabilities to events which add up to one for a complete mutually exclusive set of events that the probabilities are positive between 01 and so forth um and in particular it assigns probabilities in a in a consistent way um and I'll explain a bit more what that means so suppose this agent is placing bets on the outcomes of measurements on some physical system and we're going to assume that they hold certain beliefs about how the system responds to those measurements the first set of beliefs uh again this is a high level if if you want to know the actual assumptions you'll have to look at the paper um or ask me about it afterwards but there's a set of assumptions that are generic so they they are things we would expect to hold in any physical Theory and they include things like the possibility of State tomography in other words uh you should be able to reconstruct the physical state of the system by doing a sufficiently complete measurement on it and looking at the statistics of the outcomes uh and maximality is just a principle we use use in any situation where there's ambiguity about how to choose things we will just uh use a maximality principle which kind of uh assumes the least structure necessary uh in order to draw conclusions you could also call it a minimality assumption I mean these things can always be flipped around it's a kind of all else being equal assumption so generic stuff but then there there's um an empiric inspired I call it a Proto Quantum assumption why Proto Quantum because this assumption actually itself is not sufficient uh to imply quantum theory but it it's also something which you would not expect to hold in a classical Theory um so it's kind of this is the key assumption which which takes us outside of the domain of classical physics and takes a first step in the direction of of quantum theory without presuming the full Quantum formalism and this assumption is defined purely at the level at the operational level so you can using information Theory uh you can consider things like how much data can I reliably store and retrieve in my system uh and that gives you a concept that I'll call the informational dimension of your system so you know if you have a Quantum bit for example um even though a Quantum bit is in a certain sense more informationally Rich than than a classical bit ultimately you can only store a single classical bit of information in a way that can be reliably you know perfectly encoded and retrieved uh so that the informational dimension of a of a classical bit and a qbit is two uh but then there's another concept of Dimension which this this is not conventional usage of this term but I find it convenient I call the the tomographic dimension uh which basically says remember I'm I'm assuming State tomography so there's some there's some measurement you could do on the system this is an assumption such that if you knew the statistics for the measurement outcomes you could perfectly reconstruct what the state of the system was and then you can ask a question well what's the minimum number of outcomes which that measurement needs to have so that's what I'm calling the tomographic Dimension and essentially our our Proto Quantum assumption is that the tomographic dimension is equal to the square of the informational Dimension uh I know that's a lot to take in um if you want we can come back to it it's not super important for what follows but I thought it's worth mentioning that this assumption is is inspired by experiment there's no reason why out of the blue somebody would believe that this should be true in fact in classical physics it's not true classically the tomographic dimension is exactly equal to the informational Dimension um so the only reasons an agent would believe in this particular assumption um would be because of uh trying to explain statistics which we have from measuring Quantum systems among other reasons and our main finding in this old paper is that if the agent assigns their probabilities according to these two sets of assumptions then on pain of inconsistency in other words in order to be perfectly rational and consistent they would have to assign their probabilities according to the born rule so even though we haven't assumed the mathematical formalism of quantum theory we have found that just a a minimal non-class IAL assumption is already enough to get you the the born rule exactly the the quantum born rule um so that's quite interesting I I mentioned here a Dutch book if you're wondering what that is it's from the it's part of what we mean by a rational agent in the basian literature a Dutch book is a series of bets uh which the agent would agree to anyone taken individually but if you consider them together uh they would um be irrational to accept so it's kind of a litmus test for whether an agent's beliefs are uh internally consistent the point is just that the agent would be irrational unless they use the born rule in this case so what what does this mean what's the upshot of this result well putting it in context it's important to emphasize that this is the first time that I know of um that the born rule is derived from essentially pure decision Theory you know plus some pretty minimal empirical assumptions without presupposing uh the quantum mechanical formalism by which I mean things like Hilbert spaces unary maps and so on you know complex numbers all of that previously in the literature the born rule has been assumed as an axiom um just posited uh that was how it was first introduced by Max borne himself um and there have been attempts to derive it from decision Theory but they usually need to invoke uh some of the formal structure of quantum mechanics such as unitary Dynamics um so so we've really made significant progress compared to that literature but I think the deeper point is that this shows that born's rule is far more Universal than quantum theory um it actually applies in a range of settings where your theory might not be quantum theory it might be some more general theory that's just not classical um and it it really just stems from some fairly basic assumptions about what the agent uh believes about the system uh and and you could say one conclusion to draw from this is that a perfectly rational agent who has the right kind of perceptual apparatus you know in order for them to see these empirical Quantum effects in the right kind of environment uh would be uh well would would essentially be forced to use born's rule to to make their decisions well that's nice uh and it got us thinking just how Universal is it so we we've been talking about rational agents who explicitly make decisions using probability Theory that's pretty Advanced for an agent that means that they they can think they can reason explicitly they they have minds and Consciousness and not just Consciousness but mathematics formal mathematics you know they can write down probabilities and so on and we were wondering well but this the elements here are so simple that it seems like you might not even need that much firstly what if the agent wasn't perfectly rational there's a lot of literature studying uh deviations from perfect r nationality in uh in conscious reasoning agents which is super interesting but we went to an even more basic level with and we were kind of inspired by the the act of inference the ant colony paper um which which is why we cited it in that work um because that that work kind of inspired us to wonder whether simple organisms like ants which definitely don't have any explicit representation of of mathematics are nevertheless able to behave in a way which conforms to some fairly sophisticated abstract rules um so we set out to discover whether a a really simple simulation of an agent um could end up behaving in a way that that would conform to the the quantum born rule without having any explicit knowledge of quantum theory or even being able to explicitly use probabilities so in order to uh actually carry out this research there's a lot of things that one has to decide so there are so many ways that you might think of modeling the simple agent and uh you know to say nothing of the question of how to model the environment so I'll talk about both of those in turn first of all we want our agent to be ignorant of quantum mechanics as I said uh but it's it's survival or or there should be some uh success parameter which depends on how well it's able to predict the outcome of a measurement on some Quantum system the idea being that that it's through it's me ments on on Quantum systems that it will ensure its own Survival and that's why it will ultimately we hope learn to behave in a way that respects the the born Rule and so our agent will um learn from its experience and to do that we we'll use a kind of action response feedback loop so at each moment the agent will place bets in which it it kind of tries to get the probability for some uh outcome to occur and then depending on what happens and what the actual outcome is it will get some uh reward SL penalty uh and that will then cause it to adjust Its Behavior for future betting and we made some additional simplifying assumptions we we really wanted to start with the the simplest thing we could possibly think of just as a as a preliminary test um and in many ways we uh perhaps oversimplified but um we also did quite a lot to you know even though our our algorithm you'll see is not very sophisticated um we also helped it quite a lot in other ways so I'll explain that so we assume firstly that it's Marian in other words the decision it makes at any given moment um should only depend on on the average um expected reward for for each of the possible actions it could take um so it doesn't remember exactly the sequence of rewards that it obtained for a given action it just remembers the relative um the the average expected reward for each one um so you know it kind of has a memory just just in terms of its state at a given time but that state only keeps the information of the relative weightings um and I call it a Proto basion agent it can't be aasan agent because it's not using probability Theory it's just reacting in a kind of a dumb uh simplistic way but it's Proto agent in the sense that if you give it enough data so if you take the limit as um as the data goes to Infinity uh you want to find that it will behave exactly the same way that an intelligent conscious rational basan agent would um so that that would kind of be the limit of of um you know the limit of large data corresponds to the limit of perfect rationality and when you look to lower amounts of data you can think of that as a weakening of perfect rationality due to the finite resources of the agent and that's what we wanted to investigate what happens when you go to smaller amounts of data which which is what you would expect for um a real organism can't sit around collecting data um you know without paying some kind of cost it doesn't have infinite time or or energy and uh a very natural way to implement this kind of algorithm is a reinforcement learning algorithm and uh this is a sketch of how it runs um in our implementation so at each step s and for each possible outcome J of of whatever measurement we consider I'll get to that um the agent has to choose a bet b of J from a discrete set of n options uh which take values in the interval between zero and one so the idea here is that the agents when in choosing a bet um they are guessing what the what essentially what the probability is for the outcome J of course they don't use probabilities explicitly for the agent this is just an action the prob you know the the reason for us putting it in this interval is because we know as Outsiders that at the level of analysis these things will in the limit of large uh step large numbers of steps s um these bets should correspond exactly to probabilities um but it's from the agent's point of view if you like this is just a discrete set of n possible actions that it could take and that's really all it means to the agent and there is an interesting issue here because you would say well if these things are supposed to correspond to bets on probabilities we're kind of fundamentally limiting the agents um because we're not allowing them to pick any real number between zero and one and that's an interesting point um we had to do that because you can imagine that if if the agent were allowed to pick any real number and they would start would say a uniform prior uh on the unit interval then they would never actually choose the same action more than once the probability would be um vanishingly small that they would ever repeat an action and an agent that behaves like that just has no hope of surviving I mean or you know you can't really work with that so it's important that the agent is able to repeatedly choose the same action so that they can learn what kind of responses they get there might be more sophisticated ways to deal with this uh but we found that actually Beyond a certain threshold of the the number of choices n the value of n doesn't matter um so as long as you have kind of a fine enough splitting up of the interval that gets you you know approxim close to whatever probabilities you want to give uh it works well enough so the agent chooses the BET and uh then the measurement happens so again I'll discuss the implementation of the measurement next but the measurement results in some outcome which which I'm calling J Prime and then we check whether the current outcome that we're making bets on is equal to J Prime and we Define this parameter e so e is one if we're looking at J Prime and zero if we're not and then the reward is basically just the difference uh between the agent's bet and E which is 0 one um and in and and you take that to the square and subtract it so why do you do that this is called the quadratic loss function um and the usual motivation is that this is um the reward function which guarantees that if if you were actually a evasion rational agent assigning probabilities explicitly this reward function guarantees that uh the bets that you place uh will match your um subjective probability assignments so again this comes from our demand that the agent be a Proto basan agent basically using this reward function guarantees that in the the limit of many steps the relative uh the weightings that the agent assigns to to the the bets that it chooses will correspond exactly to the the actual probabilities for the outcomes so that's why we picked it also because it it is mathematically the simplest possible um uh reward function it yeah I mean it I call it a reward function but it's negative reward so it's actually a loss function technically and the agent is just going to optimize that to try to minimize its losses and um so okay how does the agent do that what what strategy does it use now it's made a bed um some outcome happens and and it receives some feedback how does it then choose uh what to do on the next um on the next step and we use a pretty standard algorithm for that called an Epsilon greedy algorithm basically there's some parameter Epsilon which is supposed to be small um meaning significantly smaller than one uh but not infinite tmal you you can kind of play around to make it what you want and with probability Epsilon uh the agent just chooses randomly so it kind of just chooses you know to see what will happen without any particular reason but then most of the time probability one minus Epson it will go with the safe bet so it'll pick the action which in the past has given it the highest return and this is a pretty intuitive algorithm when you're thinking about actual organisms because uh you know if you just imagine in everyday life you're picking what restaurant to go to is a classic example some of the time you want to um you want to just go with a safe bet you know the restaurant which you've been to before and you know that it's good but if you were to just do that you would never actually uh find potentially better restaurants so sometimes it's worth taking a risk and just trying a random new restaurant just to see if uh you know there might be something better out there so there this is a classic you know uh exploration versus exploitation balance and and the parameter Epsilon 2 how much the agent favors one or the other and again it's a very natural thing to pick in the context of models of actual uh organisms so finally let's talk about the environment because this is in a way where the action happens if our agent is going to have any hope of learning to behave in a way that's sensitive to Quantum Mechanics you know at least that conforms to the born rule then there has to be something special about the environment um if if we just put it dumped it in in a thermal bath or you know in some environment that could be perfectly explained by some classical physical model there would be no reason to expect the agent uh to behave in a way that follows the born rule because the born rule is inherently a non-classical uh you know it's applies out inside the domain of classical experimental physics so what what do we need uh for our environment to to have that sufficiently rich structure basically we need to make sure that the measurement statistics whatever measurement we pick on on a Quantum system has to be a rich enough measurement that it exhibits um Quantum structure well it has to exhibit enough structure that it can't be explained classically by some classical model of the environment and that led us to use something called an informationally complete uh Quantum measurement you know povm um and you you also need to consider states of the system that are being measured you need a variety of different environmental States and that also should be informationally complete um so together this is often called a tomographically complete set uh because the idea is that if you know the statistics for for the measurements for all of these states uh you can reconstruct the mathematical form of the quantum state so it's kind of a safe bet if you have an informationally complete measurement and and set of States you can be sure that the structure of quantum theory is represented within the statistics now this may be a stronger assumption than we needed to make but as I said it's definitely sufficient um and this is one of the ways that we helped out our agent made their life easier because realistically um you know we we don't make any claim that uh an hypothetical agent that was evolving in in a Quantum environment would actually be doing this kind of measurement um and indeed it's not even clear what what that would even mean you know what kind of measurements they would be doing so we're just avoiding that whole um Thicket of questions and just saying okay let's just do whatever would make it easiest for the agent and we we go even a little bit further to just to simplify our own lives as well uh we assume that this measurement has a certain mathematical symmetry property uh it's what they call symmetric information complete povm we like to call it a seek SI I please don't call it a sick um they're really interesting mathematical objects um John knows all about them and I'm sure we'll would be happy to tell you anything you want to know um but for our purposes what what's great about them is that they really simplify the form of our equations um and it turns out that at least in in the lowest number of Dimensions where this is interesting you can actually Implement them experimentally which I'll talk about soon um so in this article we actually didn't do an experiment we just proposed one uh we did a simulation and that's another way in which we made life easier for the agent because in a simulation uh you can assume that your um Quantum states are exactly what you want them to be you know pure States no noise U measurements you can assume are perfect and again realistically If This Were an organism the kinds of measurements it would be doing would be completely messy the kind of States describing the variant would not be pure States they would be thermal they would be mixed um again we're just Sid stepping that and saying let's just see what what makes it easiest for the agent even in that best case scenario how well would the agent perform uh in a simulation and you know we can propose an experiment to kind of see how that would play out I wanted to just show you this slide to give you an idea what it would look like to do a symmetric information complete measurement in the lab um so so this is um something that they can do here in Rio um actually have done um it's a really neat way of implementing uh this kind of um actually not just the metric but any uh kind of for outcome povm so this is an apparatus called a displaced sagak interferometer in Quantum Optics um the idea is that you um so that's a laser beam going through there that well it's actually not laser it's the path of a single Photon that's coming from um spontaneous parametric down conversion which produces pairs of entangled photons and you send one Photon into this apparatus following that that red line uh and the other one uh goes to detector which will um indicate whether it's partner photon is present that's important because it's a spontaneous process you don't actually know when there's a photon in there unless you grab the partner Photon so the presence of the partner Photon tells you yep now there's a photon in the apparatus okay so the other Photon goes into this complicated looking thing um I won't walk you through it but you can see there that there are four different output ports which label the four possible outcomes so here we're talking about um a dimension A system that has informational Dimension two uh but it has tomographic Dimension four and since the seek is information complete it needs to have four outcomes um the reason that it its uh informational Dimension is two is because here we're using essentially as a cubit we're using the polarization degrees of of the single Photon so that Photon will go in there and it'll pop out at one of these four detectors and depending which one it pops out at that gives you the outcome of your measurement and the the quantum system which is kind of representing the states of our environment is the single Photon itself which can be in different Quantum superpositions of polarization so it's a very contrived uh implementation but again it's like the simplest thing you might possibly consider and you can imagine that your agent somehow depends on its livelihood depends on predicting where these photons will where where the photon will pop out in each in each step so every time you send a photon through uh the agent tries to bet on the likelihood that it will pop out at each of these ports and every time it um you know the the Photon pops out somewhere then depending on what bets the agent plac they will get rewarded accordingly um so this is how one you know could implement this um now we ran our simulation and we we simulated exactly that setup um as a kind of Prelude to to see what we should expect and we had a working hypothesis going in um which is that the agent should learn the B rule fairly easily and our reasoning was that we've gone through a lot of trouble to make this experiment you know this proposal as ideal as possible you know we're assuming pure States perfect measurements and so on so how hard can it be you know this is like the most Quantum thing that you could possibly do uh in dimension two you cannot get more Quantum than this um if if you like it's like you're saying this is an environment where we we've dialed up the quantumness to maximum um so come on it can't be that hard but it turns out it is pretty hard for the agent to learn to behave according to the born rule in other words um if you do an analysis of its betting strategy um you can measure how close its betting strategy is to the to the quantum rule the born rule um there there's a bit of math involved in how you do that comparison but basically uh you can formulate it as a comparison between two two matrices and you can compute something called the hilit mid distance of the two matrices and uh you want to see that distance basically um getting down to zero ideally as the agent gets closer and closer to um making bets according to the quantum the optimal Quantum strategy now indeed if you go up to uh more than 10 to the power of five steps the agent starts to approximate um the born rule which is but that's what you would expect at that number of steps you're in the regime of large data um you know that this is like at that point the agent should be by construction it should be behaving like a perfectly rational agent so there's no surprises there what did surprise us is that um it it couldn't get such good performance without such a large amount of data so it seemed that no matter how we fiddled with the parameters um we just couldn't get it to perform better than that and this is an open question I mean whether we could think of more clever algorithms more sophisticated algorithms that could get it there but there's a subtlety because you can't just pick any algorithm that would give you Optimal Performance um because your ALG algorithms doing double duty uh it's on the one hand it has to be good at uh detecting the the quantum effects in the statistics but it also has to be a plausible representation of an information gathering organism that's concerned with its own Survival and it's that second point that makes this all interesting um because that it's not super well defined what class of Agents meet that description so I I'll just mention um that somewhat frustratingly we found that even you know at relatively low numbers of steps like 500 steps um the value of n like the number of possible bets the agent can make doesn't seem to matter much so I mentioned that earlier on and I guess that's kind of intuitive um because realistically when we make bets we don't make bets of uh you know values below one cent you know like all our our decimal places all terminate at two when it comes to placing bets unless you're using Bitcoin but let's not talk about that you know um you know so the the idea is it's natural to have a kind of coar graining of your your U bets AKA probabilities for the rational agent uh and and that shouldn't really matter as long as they're they're find grained enough um and indeed they don't that something that was more of a surprise is that Epsilon doesn't matter at at relatively low step counts you can see why at very large uh data sets Epsilon shouldn't matter remember Epsilon is the probability for exploration trying new things um the reason is that as long as you have some nonzero Epsilon when you run enough steps that will be sufficient for the agent to explore the whole Space of possible actions many times um so you would you would expect that for a sufficiently large data Epsilon should stop being important um but we didn't quite expect that it would stop being important so soon um so that's kind of interesting but what the upshot of this mean is just that the main limiting factor on the agent's performance turned out to be um just the amount of data itself just the sheer amount number of steps um so the lesson that we drew from that is that unless the agent could afford the time and energy needed to acquire this much data um you know and think 10 to the five steps depending you know what field of science you're coming from that may or may not seem like a large number um but you know if you think of things that an organism has to do in order to you know to take an action and get a response from the world you know eat eat a piece of fruit and see if it kills you or not you know that kind of thing 10 to the five is pretty demanding um and so you know if we Grant the 10 to the five is a um unfeasibly large number uh for a t a typical you know a reasonable model of an agent um then we would have to conclude that it's just not going to learn to behave in a manner that reflects uh the finer Quantum structure of its environment even when that environment is explicitly quite strongly Quantum and this was surprising to us uh we we really didn't expect that now it's difficult to draw a definitive conclusion from this um but we are tempted to say something like the following um in inspired by there's some work by cognitive scientist Donald Hoffman some of you might might know of it who he argues that in general uh there's a selection pressure against organisms evolving to perceive the world as it is truly um that in fact organisms which are too accurate in their perceptions of the world will be um selected out uh it's just not not an Adaptive Advantage um and he he argues essentially that true information is not necessarily useful information that what we're evolved to perceive should definitely not be expected to be what's true but rather what's relevant to our survival and that made us Wonder um you know we pose the following question based on these preliminary results could it be that um could Quantum sensitive Behavior ever be beneficial to an organism survival or is it just too hard to learn um you know if we could make more formal and well- defined and rigorous definitions of these terms this would be a really interesting question to answer uh the problem is that to really decide the issue it seems that we need a generally accepted criteria for what we mean by life and what we mean by viability of an organism that would then constrain the space of of allowed agent models you know as I said there's a subtlety in making sure that you're not just picking an optimal model from a performance point of view but choosing a model that uh plausibly represents uh an actual living agent and as I said our model in some ways it's too constrained uh because our algorithm is so simplistic you might think that there might be algorithms which are still realistic models of Agents but which might perform better because they just have more uh more more possible decision- making Machinery available to them but in other ways our model is not really constrained enough uh because as I said we're we're assuming ideal measurements uh and and so on so a more General approach is needed to be decisive um our preliminary results are suggestive but I wouldn't say they're conclusive so this is the conjecture just to put it up on the screen even if quantum effects are strong in the environment Quantum sensitive life is generally selected against by survival pressures I.E is not viable in other words maybe conjecture maybe the only route to Quantum sensitive behavior is via higher order cognition like us you know we humans you know we're building quantum computers we're definitely behaving in a way that's sensitive to Quantum Mechanics but that's through explicit reasoning um the conjecture is that there's no shortcut uh that there's no way a Mindless agent could evolve adaptively to become sensitive to Quantum effects at the behavioral level um just through Evolution uh somehow you know knowing quantum mechanics has to be like an accident of cognition a bit like appreciating music um I mean it's a pipe dream I don't know if we'll ever be able to resolve this conjecture but I put it there to stimulate discussion so thanks again for listening and uh I'll open for questions thank you perhaps John if you'd like to give a first comment and then Ander welcome sure um thanks Jack uh I think you pretty much covered all the bases um and somehow I feel like I learned a little bit about our paper just heing you sketch it just now even though you know I'm one of the authors uh but yeah maybe I'll just reiterate a few of the things you said um because are maybe the points that I think are most important to to really take away because there's a lot of sort of quantum detail in here that doesn't matter for the kind of conclusion that we want to talk about maybe um and so I guess the main thing is that if you really had an ideal basian agent well they would do what they do also you teach them quantum mechanics and then they behave in a certain way the key then ultimately is that behavior what we want to figure out is whether there could be a shortcut right so we came to cubism um from the idea that decision Theory uh can explain the born rule like you said in our previous paper but um real agents are part of the world they're not ideal they are limited and so you know the question is whether there's a shortcut to the same behavior so that from the outside it's sort of approximately indistinguishable from an ideal basing agent and again we thought it was really cool that uh you know you can model things like an ant colony as a basing agent even though of course it's not writing down probabilities and utility and maximizing expected utility and all of those things it's just that it takes behaviors that are sort of indistinguishable from that whole General process um so if there were a shortcut then um then you don't really need full-blown basian agent concept right that would be the idea so and then okay so that that's that's the motivation as jacqu already covered I'm not really saying anything new um but we came at this in just the the very first order kind of way I think because what we did was we took the basian agent concept and weakened it in pretty much the weakest way that you could weaken it uh we have agents here that are making bets they don't know probability Theory but it's very thinly veiled like there's we we basically arrange so that in the infinite data and continuous limit then their bets are probabilities full stop um and in order to be coherent they need to obey probability Theory and they need to obey the born Rule and that infinite data would just inevitably lead them there and indeed we do get there when we get enough data um but if it had been the case that sort of a low amount of exposure to their environment allowed them to get pretty close to the born rule that would have made us think okay well uh maybe the the whole idea of these higher order thinking beings that kind of can Implement something like basian decision Theory and hbert spaces and so forth that's Overkill and what you really get you can really get all of this behaviorally and what actually matters just from a simple agent-based model um and we found the opposite basically we found that it took a lot of data and a lot of Jerry rigging and helping and idealizations and you know simulating things without noise or anything like that before we can actually get the agent to behave in a way that is close enough to the born rule to be meaningful um so that is some evidence as jock said in the direction of well maybe we really do need these higher order agents that uh have to use basing decision Theory and actually you know think in abstract and so forth but it's also I I I think we shouldn't forget that it's it's definitely possible in fact maybe even likely that we didn't weaken the basian agent framework idea enough in our simulation um and I say that because you know the bets here are sort of different probability values uh what if we had something far more heuristic um and it's hard for me to think about how we would actually compare it to the real born rule in that case but um but I don't we've certainly not ruled out the possibility that uh a different kind of simple agent model um could effectively learn to behave in a way that aligns with with quantum theory um with lower resource cost um in this in the way we we did generalize it it's sort of the the goalpost is still you get everything that you get in the basing agent setting um and so maybe by definition it requires a lot of resources to to win that game it's not clear but anyway way those are pretty much my my comments uh and yeah awesome thank you thank you Andrew for joining would you like to give an initial comment and then I'll read any questions so then we'll continue the discussion yeah I'm not really in a position to uh comment much because I didn't get to read the paper but it was a very interesting talk the one thing I want to ask is could you show the slide on the dchb again uh that's around the time I showed up I think and then yeah was it the a couple slides later or was it this one this one maybe a bit later yeah yeah yeah here we Rec what was going on here because it reminded me of something else uh that we've seen with Chris Fields Daniel but I I think I missed the explanation so um it reminds me of contextuality right in in in in Chris's work like but I might be messing it up I didn't I didn't hear an entire explanation do do you want to know uh how does how do we use a Dutch book here like what role is it playing is that what you're asking yeah no I sort of got it right I think I think um any one uh decision here on its own would you know you could you could approach optimality right but when you start taking into account several possibilities that's when you have the the dasb phenomenon is that is that right yeah uh I I think so if I understood you right um basically it's um if you anytime you have an agent who has a set of beliefs um you know expressed as probability assignments to some set of events that they're concerned with then there's always going to be a question of whether those those different um uh constraints so so the they beliefs will generally be expressed as some constraint on their probability assignments right and they might have a bunch of constraints and you want to make sure that those are all consistent with each other so the Dutch book is is just mathematically a really nice way of testing that um basically if you can find the Dutch book using the the agent own probability assignments that means that their set of beliefs like the set of constraints that they're trying to uh adhere to are mutually in inconsistent did I did I explain it well John uh yeah that's that's true I think um one other thing to point out here maybe that uh Ander might be asking about is um so the two things you've said you you've emphasized here essentially well actually you only really emphasized one of them but in general the Dutch book idea is like a logical consistency between the different beliefs that you have and um like for instance if I said there's a 60% chance it's going to rain today and a 50% chance it won't rain today well I can't hold both of those beliefs and the idea of a Dutch book is that I could ask you to pay a certain amount for one ticket that would pay the dollar if it Reigns and a certain amount for a ticket that would not that would pay you know 50 cents if it doesn't rain and then you just lose money for sure the Dutch book idea is You're vulnerable to a sure loss um so that's a purely logical constraint on your beliefs um but the idea that was motivating this previous work was that what if that's you have that of course being consistent is important but you also perhaps need to be consistent with some particular kind of characteristic of the physical world so there's a sort of coherence that's imposed logically and a coherence that's imposed physically um and in the context of informationally complete measurements just consider a single measurement and just your probability for that well logically the only constraint there is that you have a probability simplex and you don't assign something like probability 110% to to some event or below zero okay so it has to be between Zer and one inclusive but for an informationally complete measurement um physically we just know this empirically uh quantum mechanics implies a restriction of the probabilities that are valid for full stop for the assignment for a minimal informationally complete um measurement and so Quantum State space the the set of Val Quantum States you can have corresponds to a proper subset of a big informationally complete probability Simplex um so that's another kind of um uh consistency you need to keep in mind if you want to actually be consistent with logic and with sort of physics in the world I see thank you yeah so I think I think I sort of get it and and it the point is well taken right because um the whole I don't know if you guys are aware of the course that happened last year but one of the things that Chris mentioned with uh the quantum framework of active inference is that you have this this idea of contextuality which happens whenever you have non-commuting qrfs the quantum reference trins which is you know what an active inference agent deploys to perform measurements and actions and whenever you have uh non-commuting qrfs deployed you cannot I think basically the idea is that you cannot have well- defined joint probability on on the on the boundary uh so it's morally very related but I will have to check the details but thank you guys um actually now now I I get what you're aiming at yeah I it's it's not just morally related I think it it is um the same thing or or closely related like formly because actually the way that that um our co-author on the paper Blake Stacy put it is that it's an assumption of no hidden variables um which amounts to contextuality basically saying that you uh there can't be a joint probability distribution I mean let me let me try to say something that is both precise and probably correct if if you believe that you're dealing with a contextual phenomenon you know that that you have measurements which are non-commuting in in the relevant sense then I think you would need to have something like our assumption to there is although I'm not sure the it would give you in quantum theory it would then two would definitely hold so this tomographic Dimension is information dimensional squared because in quantum theory the the minimal number of outcomes for an informationally complete measurement is D SED the Hilbert space Dimension squared so but whether if you look in a more General probabilistic framework if you have some definition of contextuality it's not clear to me if that would give you the squared it would give you something something like this so you would definitely I would expect you to have a non equality here so it would be non-classical in the sense that your tomographic dimension should not be equal to the information Dimension when you have contextuality uh proof pending I bet that that's true I I believe it is the case that the Assumption of there be the possibility of a non-contextual hidden variable model uh is possible to formulate in terms of these proper subsets of quantum State space that I was talking about I mean of of the informationally complete Simplex that I was talking about it just so happens that Quantum State space itself pokes outside of that and so that means that in general it's not compatible with the idea of a non- textual hidden variable model or to put it more positively if you want to talk about hidden variables which we don't personally but if you do then you have to have a contextual model well thank you that's very good awesome okay I'll read some of the comments in the live chat um and then I'll I'll have a few things I wrote down so um the text a little small but RV says is the agent always trying to guess the same Quantum State um well so first the point of clarification the agent isn't really trying to guess a Quantum State uh they're doing something much more basic they're just trying to guess what the outcome of the measurement will be um and well they they're trying to guess the probability for for each outcome is it a fixed coin flip with a static or changing probability so I mean those those probabilities will be different for different Quantum States uh you know of that for instance in our implementation you your environment is is just a single photon with some polarization State and that polarization State depending what it is will give you different probabilities to get the outcomes and the answer is yes we do need to consider different Quantum States uh the reason is because if you just hold the quantum State fixed you your statistics will not be rich enough to uh to be distinctively Quantum so in that case you you would be able to explain those statistics with a classical model and you would not expect your agent to be able to learn anything Quantum in that situation so you need to have not just several Quantum States but Quantum states which are sufficiently varied across state space um that it that it [Music] um yeah but when when an agent when an agent is trying to learn a certain probability though we assume that they're in the same context where they have the same state and the same measurement and they repeat that a bunch of times so that might that might have been the question I just want to make sure good point yeah yeah I didn't clarify that yeah so the the you know we kind of the agent is allowed to know like that it when it's in a different uh environmental context corresponding to a different state um so it can you know put the relevant labels on its um Bing Behavior awesome very connected with context switching and attention um I'll read a question or comment in the chat Andrew Pasa wrote active agents priors over observations their preferences which is what generalizes and includes the reward maximization in the pragmatic value and then expected free energy ads in the epistemic value actin agents prior over observation their preferences as survival related homeostats expected free energy drops the need for defining an Epsilon for random SL exploratory Behavior h i I have difficulty in responding to that because I'm not sure how free energy connects with this but this is something I wanted to ask uh maybe this is this might be exactly the kind of reason why we need to talk with you guys because I didn't even understand the question but clearly you're coming from a a background that um uh knows more about the agent modeling side of things than we do let let me pull back and just a few of the things that I wrote cuz there's kind of a a a triple intersection that that's funny and and led to to this through citation LS Etc so kind of from how I understood the journey and the the the generalization SL weakening but experimentally designed and the constraints of of the real experimental setup and the more generic equations and also weakening those or figuring out how they could change so you set out from the quantum born across the real experimental interfaces and got to some of these multiscale possibly adaptive Dynamics like reward surprise Fitness that are tological about situations then in octave inference there's kind of a a dual origin which is like one of the figures in chapter 1 of the 2022 textbook with this idea of active inference in the middle or coming from or two the low road and the high road so the low road is like the generalized sensory motor Loop so kind of like cybernetics or with the embodied connection like robotics or embodiment and then also the high road is the basian mechanics free energy principle principle of least action for basian all of those kinds of things so those are the first two threads with the quantum born empirical setting then the active inference kind of well there is this sequentiality to behavioral updating on the inbound sensory and on the outbound action which is like selecting a bet is like an action and chrisfield takes that into the quantum fvp which is like more of a recent development and then the third element is like the ant infer ant which was the paper from 20121 so lot to say about ants but the colony for anal Iz ing The Colony as a phenomena it it highlights and it starts from the lateral interactions amongst nestmates like the collective Behavior and the interactions with the niche including like different kinds of pheromone Decay or something like that like a sunny context might have a higher rate of Decay and then also there's this kind of pragmatism of measuring anything which you have in the laboratory in the quantum setting and then also also there's that experimental constraint in the laboratory for ants and also in the field for ants so it's kind of like the pragmatism and the real finite constraint and kind of our experimental reality and then it's just interesting that you came at this from the best experimental and updating process about systems that that many might say are non-cognitive or sub cognitive or something like that or just differently and then also but from the more generalized cognitive side that has led into Quantum Baye whether or not there's like a mechanistically Quantum effect in the brain that doesn't mean that the decision Theory isn't already transferable what do you think orot in there I'm busy absolving that yeah you know you mentioned I mean one of the things about this work on on active inference is the multiscale structure and this was something that in our paper we kind of handwave towards the end uh about our work really focusing on I guess what you were calling the low road which in the sense that we we thought of our little Proto agent as more like an ant um but then we we kind of posed the question of whether if you got a lot of these guys together and had them interacting or or somehow working together you could uh kind of look at the whole system and get an emergent Behavior which you to which you could attribute uh you could model from from a kind of basian rational agent point of view um but that you know we didn't really get as far is addressing the the kind of multiscale stuff I think because we we're still trying to work out the fundamentals you know pure action response Dynamics I mean maybe we need the multiscale thing in order to meaningfully generalize or to weaken like that might be the the right thing to do um and it may maybe make sense that uh it's so hard to uh make a simplified sort of non-cognitive approximation of the basian agent model in the way that we did but you know we did it this way because we didn't know any better essentially well yeah it's it's it's awesome two of the things from Chris fields's course the physics as information processing was also relaxing sometimes constraints about space and time like having agents make their own spatial temporal reference frames so rather than just plugging in agents into kind of a grid work that's defined by an observer whether or not they're modeling themselves um and then also just the the environments and the partition the interface the blanket all those different ways to describe the interface between internal and external States or what whatever notation or variables are used so that's kind of like the communication setting like Alice and Bob but then maybe Bob is the ground and its ferone distributions as actions but then it's not about like whether or not that's like an action of the ground it's like well that's being modeled by a person making another finite model so it's a map territory for how they're drawing it so there's a lot of interesting pieces and great great topics to go into yeah one other connection is you said something about General born extending into the unobservables and this is like one of the key moves with the separation of observations and latent or hidden or external States so there's like a the ambiguity Matrix which is just a bidirectional mapping what would the measurement distribution be from a hidden State what does this observation and then the observations can be attached with epistemic value and a pragmatic value value related to like the cost of sampling and just the preferences against expected future observations those are all kind of like cognitive motifs like we could explore what experiments do or do not show that a nestmate plans can you falsify or put a probability distribution over the idea that it's doing something Beyond its immediate sensory blanket how many time steps of memory how many time steps of anticipation that's a model selection question with a certain labber field data set it's like well there's there could be a difference but it would require getting 10 to the five foraging runs by the same nest M but it may never take that many and so that also kind of tucks back into the evolutionary priors and the distributional starting position which is like always a problem in applying basian statistics and then there's like a kind of neat Fitness oriented way to give the prior yeah I I mean and and also I mean use the nest mate language which is a fun fun thing to talk about uh I mean in our s like one single ant alone is pretty useless because it can never live long enough to get 10 to the five things but if it's got a bunch of nestates and they can communicate with their phermones and so forth then maybe 10 to the five isn't a lot when you have a bunch of of Agents interacting and so forth It's it's a great interesting debate with the ant colony world and what's interesting about ants I mean among things is they're obligately Colony living whereas other hopin like even the bees and the Wasps they have a lot more variability with different life histories but then the ants have the obligate us sociality so that kind of like the termites or different than than those other ones like in both those or the any obligately social form then the unit of Fitness can be kind of targeted as and so it sets a norm not the only possible Norm but it's like Optimal foraging Theory it's like is it about one nestmate getting the most food per unit time it's like maybe if that were a special special case of water loss and time and Colony hunger and the seasonality then it could be considered optimal but if the optimal strategy is not then the she amount of foraging activity or type of it it can't be considered like it's only optimal within an evolutionary context otherwise you're just saying who is foraging more right right this is a bit off topic but I uh it's a a wild idea that just kind of popped into my head now that we're talking about actual organisms like ants um you know it occurs to me that most of the living creatures that we could think of off the top of our heads so far as we know uh are not specifically sensitive to Quantum effects I know there is a literature on Quantum effects in biology um but it's usually really down at the chemical level like in photosynthesis um or or uh but you know I wonder like there's work that you know the human eye is it it they know that the the cells in the retina are sensitive down to the single Photon level like in principle just a handful of photons can trigger a retinal cell fire and there are experiments kind of working on I know because my my wife who's also one of the co-workers on this paper is working on this stuff here in Brazil um but uh it makes me wonder if like maybe there are because there are creatures out there with some pretty amazing capabilities like there's the mantis shrimp which has these crazy that have trinocular vision and I don't know what else you know maybe there are some living creatures that we could actually get into a controlled lab environment and have them actually interacting with uh Quantum stuff you know if they're Photon sensitive you could kind of see if you can fire photons at them and get them to behave in a in a responsive way I don't know that just seems like it might be really cool I'm just throwing that out there what would it like mean or show if if there was a way to do it it would just be cool man that made me think of having the photon instead of killing a hypothetical cat it releases one like phermone for a moth or one molecule of glucose for a bacteria so and that's kind of what the synapse does with the discretization into the packets and then to the neurotransmitter discretization level with release and and that also relates to something came up a lot in the Chris Fields was the interplay of of kind of classical and non-classical state spaces and the interface as being like the more classical barrier and then different aspects of that when it's interacting with the quantum Alice and Quantum Bob Andre want to add anymore where where else do you think it would like connect yeah that that was an interesting thought by Ja um but my question to you is don't you think that the the issue of Agents being able to observe Quantum effects um you know I I see it related to the FP in the following way like one of the latest papers he talks about the FP driving compartmentalization and you can imagine that as an organism you know becomes larger and more s sophisticated they'll have more degrees of freedom available to be able to pick up very subtle Quantum effects and and even more outter idea you know it almost feels like no difference to how we need High energies in accelerators to observe real small stuff you know yeah one one other kind of topic I'd love to hear more about was the fourfold nature of the experiment because that made think about a c a collision of the particles and how that's often thought of as like two interacting components however there's also like let's just say that there are two real interacting real question mark then you have an interface and then like a s and an O you have observation and then at least a measurement frame that's been learned or calibrated like the a matrix projecting on to Like A P value or base fact some other kind of other further Downstream um analysis so it's like are there four things there and then what are those four and so what is it about the fourness of the empirical setup and how is it exactly two for the exponent or how does is that variable or is that always an integer that too is purely from Hilbert space geometry and so in so far as we use quantum theory and well in so far as the model is right and according Associated to any system you can always write down a Hilbert space of some Dimension then it's just a matter of mathematical fact that the state space only spans a d s well actually d^2 minus one because there's a normalization but anyway it's a D2 dimensional operator space which is where Quantum States live um and so yeah we can't you can't it can't be d2+ one or d^2 minus one unless you're talking about something other than quantum theory um and so far we don't seem to have anything other than quantum theory so that's yeah that that empirical part I mean we call it empirical but it's empirical at the level of is this Theory we've been using for 100 years actually right not empirical at the well we measured this Mass and it looks like it's within this and this and it's plus or minus you know so it's it's like pretty solid it's a bit of a lie to call it it's not purely empirical yeah it's meta empirical it's it's met empirical and it's pragmatic in the sense of pragmatism which isn't uh some kind of pure utilitarianism but pragmatism just deals with the pragmatic aspects of of operations okay yeah like magmatically if you if you want to do state tomography you're going to need at least D Squared outcomes and they better be good ones yes yeah and then an interesting extension into the behavioral space where neither kind of I mean Mass bace classical models but even kind of classical inspired models don't describe all behavioral data and then like if the observation has dimensionality n like n sensors for Sensor Fusion then a has N squared because it's square or second powered to to map all the Matrix mapping all by all observations to Hidden States and then B which is what the control policy is exerted as a slice from which is like a behavioral collapse from makes it another Power because there's how the the S Vector changes so a kind of balloons it out but then projects it back down to some other possible space and then B uh it I squares s because it's a transition selection and so then there's a lot of interesting traces to follow there I confess that mostly went over my head but it's it's not yeah what about the plus or minus one which plus or minus one from the d^2 plus or minus one like what what would it why could it be plus or minus oh no I was I was saying it couldn't be oh okay yeah sorry Theory yeah yeah if if it were different it would be a different Theory that's what I'm saying uh yeah so it looks like it has to be um Des I mean it's something that would be nice to explore one day like what what are these theories that have different numbers that not just the squared but uh yeah too too many questions too little time we're only on a 4D live stream you can't um well what happens next or where should others or what are you going to explore well I think you know based on this conversation the thing that sounds most promising to me if we were going to take this further is the multiscale part like I think really we want to model agents or an agent or the the the the target of basy an agent has to be sort of the emergent property of many little guys I think that's that's probably the most pertinent uh thing to take from your um kind of community and that what we totally ignored in this work um and yeah so we didn't yeah we barely mentioned that in the paper but I think personally that feels like the most exciting possible way to push this direction further I don't know about jacqu yeah I think John I think you're probably right uh just pragmatically speaking it that seems like something that's concrete and well defined enough that that one could actually make progress in that direction and it would be interesting but you know just speaking from like what what is like the question that I would really like to know the answer to but I'm not even sure how to formulate it in a way that could be attacked with research is you know there's this idea that quantum theory is a bit weird because of this you know like the non-contextuality thing um so and we the world that we live in and that so far as we know all living creatures live in is not a Quantum world you know where're macroscopic thermal completely decoherent creatures know um decoherent in the sense that quantum theory just isn't important to our everyday interactions with our world and I guess I'm wondering whether that's just an accident of the fact that life evolved in in a very hot wet you know regime where Quantum coherence doesn't survive or whether there might be a deeper reason behind it that somehow if you try tried to create life under really controlled conditions where you enabled Quantum coherence to survive and be like Quantum coherence to be really strong in the environment you know imagine like if if Plank's constant were just some really large value in a hypothetical Universe could life evolve in that universe or is there something about the weirdness of quantum theory that that forces life to only exist in in uh effectively in in decoherent regime you know that's kind of bit a deep question I have um I'm sure that our very preliminary work hasn't shed any light on it but I think it did do the valuable job of raising it as a question yeah I mean because what could have happened was we could have just immediately found that even in the first attempt to weaken the basing agent thing it just gets the born roll immediately and then you can say well probably well but it also would have I mean you know it it would have said oh well we're sort of barking up the wrong tree with this highlevel basy and decision Theory approach it's not necessary um so far as we know it is necessary still uh but um anyway we didn't rule it out yeah an interesting thread there it's the paper discussed in live stream number 49 with ramstead and stiv devel with showing the kind of development and generalization of Cl classical thermodynamic infodynamics server or interface that being the basian mechanics which is the where the path of least action free energy principle all that is existing and it's like another generalization from the it's another degree of Freedom which is the analytic aspect and the pragmatically constrained reality of it for the quantum investigator so you're doing it so that's cool we're on the path we're doing something yeah well any last comments for anyone uh read the paper read the paper it's a classic it otherwise yeah maybe it be a classic yeah um looking forward to it we'll be happy to stay in touch and Ander and others and Chris fields we could explore a lot more yeah and the measurement and the quantum and we can explore with the ant multi-agent Frameworks so there's a lot of great paths I think I think jacqu and I need to read up on that and then we'll come back to you that seems like seems promising to me yeah okay thank you thanks for having us bye thanks for having us 
