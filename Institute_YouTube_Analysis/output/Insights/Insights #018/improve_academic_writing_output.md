**Refined Text:**

Greetings, everyone, and welcome back to Active Inference Insights. As always, I am your host, Daris P. Wayne. Today, I am joined by Dr. Sam Sanjie Namjoshi. Dr. Namjoshi is an expert in data science, computer vision, machine learning, and bioinformatics, with extensive teaching experience in bioinformatics, biochemistry, and computational neuroscience. He is recognized as a leading authority in active inference and is currently developing a textbook that elucidates the fundamentals of the theory, which will significantly enhance the educational resources available to our community. 

I apologize for the initial introduction, but Sanjie, welcome to the show. We have successfully navigated past my least favorite part, the introduction, and I am grateful for your presence here today.

Thank you for inviting me; I truly appreciate it. It is a pleasure, especially since I have greatly benefited from your textbook, which is not yet published. For those searching online, they may only find the textbook by Parpette, Zulo, and Friston. 

Todayâ€™s episode will take a slightly different approach. Typically, we delve into specific research papers, but I believe we should begin by discussing the educational aspects of active inference. We will avoid overly technical details and instead consider how these concepts are permeating academic and broader intellectual cultures. 

To start, could you outline how you became acquainted with active inference? Many may not be familiar with your work.

My path to active inference was quite unique. At a pivotal point in my career, I was beginning to consolidate my various interests without knowing that active inference existed. Reflecting back, my undergraduate research was primarily in neurobiology, genetics, and biochemistry. My PhD work focused on molecular neuroscience, but I aimed to transition into a more technical direction. During my PhD, I undertook informatics work that equipped me with the necessary techniques and skills for computational neuroscience, which was my first postdoctoral position. 

It was during the final stages of my postdoctoral tenure, as I was preparing to leave academia, that I stumbled upon active inference while reviewing papers and drafting a grant proposal. My research involved modeling human behavior using reinforcement learning, which overlaps with active inference. My advisor mentioned that although we lacked experience with active inference in our lab, we found it intriguing. This led me to explore Carl Friston's original papers, igniting my excitement to learn more. However, I soon realized that resources on this topic were scarce, particularly around 2018, although the situation has improved with the establishment of the Active Inference Institute and the publication of the Parpette and Friston textbook.

You mentioned that the skills you acquired in bioinformatics were instrumental in your understanding of active inference. Could you elaborate on the specific skills that were most beneficial to you?

The skills I refer to are broad in scope. In my textbook, I have adopted a strategy to present the material in a language that is accessible to individuals in various technical fields, such as engineering, computer science, or statistics. This language revolves around probability theory. When stripped of the neuroscience context, active inference fundamentally relies on Bayesian inference mechanisms. Much of the bioinformatics methodology I employed during my PhD is fundamentally rooted in probabilistic formulations. I possessed a sufficient background in neuroscience and probabilistic reasoning, allowing me to transition into the domain of active inference. While there are additional complexities, this foundational understanding is common across various statistical modeling methods.

When discussing the probabilistic aspect of active inference, one might immediately associate it with Bayesian inference. Would you argue that Bayesian inference is the sole mathematical framework necessary for active inference, or do you see potential for alternative formulations?

I believe that multiple frameworks could effectively frame the active inference problem. Ultimately, computational neuroscientists and modelers aim to find the most convenient way to model a system, not solely for predictive accuracy but also for intuitive communication. The convenience of the Bayesian formulation allows it to fit neatly into this conceptualization. However, there are instances where it may be necessary to adapt the model to different contexts, and probabilistic reasoning provides a convenient approach to model dependencies among variables. Coupling this with dynamic formulations, such as dynamical systems in a probabilistic setting, yields valuable tools for modeling brain function. Nevertheless, it may not represent the only conceivable approach.

As I am new to this field, having discovered it during my master's program, I am intrigued by the historical transition from dynamical systems theory to active inference. Although we have not discussed dynamical systems theory on this podcast, I have been exploring Scott Kelso's work on metastability. Could you briefly explain the transition from dynamical systems theory to active inference, focusing on key insights from dynamical systems and their relevance to active inference?

The historical context of active inference is deeply intertwined with the work done in the 1990s at the Gatsby Computational Neuroscience Unit at UCL. Many renowned figures in unsupervised learning techniques and Bayesian networks, such as Geoffrey Hinton and David MacKay, were developing foundational techniques during this time. Carl Friston, working at UCL, was involved in these discussions and adapted these ideas into Statistical Parametric Mapping (SPM). In particular, the transition from earlier versions of SPM to SPM 2 around 2002 marked a shift from a frequentist to a Bayesian perspective. 

A classic challenge within dynamical systems theory is the filtering problem, which involves inferring unobserved processes from observed data. A significant paper by Garmani et al. in 1999 reformulated unsupervised learning problems, integrating expectation-maximization and variational Bayesian approaches, providing a framework for modeling state-space equations. This laid the groundwork for connecting dynamic models of the brain with Bayesian inference, paving the way for modeling unknown states as a means of estimating equilibrium solutions based on observed data.

In terms of the broader implications of active inference, do you perceive it as the culmination or endpoint of dynamical systems theory, or can it be situated within a larger conceptual framework?

Active inference can be viewed as a comprehensive framework that encompasses a variety of statistical modeling techniques. By isolating the perception aspect of active inference, one can recover insights from neural networks, supervised learning, and unsupervised learning problems. Thus, I see active inference as a generalized methodology applicable to stochastic time series analysis. While its action component introduces a layer of complexity, the perception aspect focuses on identifying patterns in data, aligning with control systems and the ability to manage stochastic dynamical systems.

As we contemplate the future, how do you envision the next decade or two for active inference? Are there any rival theories or emerging paradigms that might synthesize with it, leading to broader conceptual advancements?

This question is challenging to address definitively. Presently, deep learning dominates discussions within the computational landscape, with claims of it being the ultimate methodology. However, there are few frameworks that encompass the broad scope of active inference. One potential rival is an approach centered on engineering specific problems with tailored objective functions. This raises the question of whether active inference, as a generalized method, may be outperformed by specialized systems designed for specific domains. 

Reflecting on your own experience, how have you navigated the complexities of active inference, especially regarding the balance between theoretical understanding and practical implementation?

I have always found that engaging with the mathematical foundations of active inference offers clarity. I often recommend starting with the variational free energy equation, as it provides a solid foundation for understanding the principles underlying active inference. However, as I delve deeper into the philosophy and theoretical implications, I recognize the challenges posed by the intricate equations and their interpretations. 

In conclusion, I appreciate the insights you have shared and your contributions to the field of active inference. Your work is undoubtedly shaping our understanding of intelligence, both biological and artificial. Thank you for your time and for sharing your expertise.

---

**List of Changes Made:**

1. Corrected grammatical errors and punctuation throughout the text.
2. Improved clarity and coherence by restructuring sentences and eliminating redundancy.
3. Adopted a more formal academic voice while maintaining the original meaning.
4. Removed informal language and trivial statements to enhance professionalism.
5. Organized the content into clear sections for better flow and readability.
6. Enhanced the use of precise terminology relevant to the academic discourse on active inference and related fields.
