hello everyone and welcome back to active inference insights I am your host Daris parvy Wayne and today I'm thrilled to be speaking with Connor Hines Connor is a PhD student although he just told me he just finished his PhD at the max plank Institute of animal behavior as well as a researcher at versus AI his work focuses on the apparent Theology of complex systems and especially how they can be described as conducting variational basian inference over their environment thus Connor leans heavily on active infont and the free energy principle in his analysis Collective Behavioral Systems and so he is the perfect guest for today's episode Connor Thank you so much for being here I'm super excited to learn from you um I need to put my technical hat on because your papers are are technical um but I think there's a lot that non-technical audiences will be able to get out of them and I want to start having me no no it's genuinely it's absolutely my pleasure um I feel like psychology or cognitive science likes taking the unit of analysis as the individual and then saying okay how can we extrapolate from the individual to describe group dynamics so I wanted to start very broadly with a kind of axiomatic question about when you uh study Collective systems is there a difference between Collective behavior in and of itself like what you talk about in terms of collective behavior and then the behavior of an aggregation of individuals who we can say belong to a group so is there something over and above the behavior of individuals when we talk about Collective Behavior yeah I mean this is this question is is one of the motivations for why ended up studying this and I think it ties into like what I would say is a larger unifying theme of complex systems in general complex system science I think if you could like sum up sum it up in one phrase would be more is different the whole is greater or different than the sum of its parts um and that is really evident I think in the study Collective Behavior so yeah I I would say that there's something absolutely different about kind of blurring your eyes so to speak on the individual components of a system and treating the system as a thing as an emergent thing and there's a lot of theories about whether that's like an Epi phenomenal thing is that just something that exists on on a descriptive level or does this larger thing like a flock of birds or a school of fish or a society or an economy does it in some way have like causal power and influence on these like level individuals but I like the the larger if the last like whatever 30 years of complex system science has shown us that yes there is something qualitatively different about the bigger picture than just an aggregation of uh individual components yeah I think in terms of let's say sociocultural groups the top- down influence is quite transparent I mean in terms of an economy the economy that you've function in presumably has a kind of circular causality with the agents in the economy totally I'm wondering whether in terms of more mechanical complex systems um so even in let's say simulation work is there something that emerges ontologically in terms of the actual dynamics of the group as a whole that can't be reduced to let's say just like a summation of those individual behaviors and I guess in that even if there is can we distinguish that from top- down causality so as you say you might have something which like is ontologically different you can actually say okay this is a different phenomenon but where do you see the top down causality coming in before we get to let's say languages or broader cultures or uh economies yeah no that's a that's a hotly debated topic effectively so there's a lot of work that's kind of trying to actually quantify the amount of top- down causation that there is because of course like we can always Define some set of macroscopic or coar grain variables from an ensemble of microscopic variables like say I have a bunch of particles or a bunch of gas particles I can take like averages like and come up with quantities like the temperature or the average mass or the average velocity the question is is that coar grain variable actually doing anything to that lower level does it feed back down and um my intuition is even in simulation yes there is and then people have tried to Quant quantify this there's people like um liel Barnett and uh Neil Seth at Sussex University of Sussex who have come up with quantities like dynamical Independence so there's an idea where these coar grain variables don't just act as descriptors or aggregators of lower level constituents but they end up having their own causal power and like intuitively when you hear that it's quite hard to imagine how that's possible um but it's I think it's one of the most fascinating and kind of magical things about complex systems is that basically these slower like both like spatially and temporally coar grain variables end up kind of uh accumulating a life of their own and they can in fact influence and in some ways be more predictive of the lower variables um than just taking the whole like Ensemble of lower variables as predictors themselves um I don't to be quite Frank although I'm quite confident this exists I don't have a great intuition for how that's possible because it kind of flies in the face of the last you know 200 years of reductionist science which is basically saying that the only causal direction is up everything starts like you know with gluons and quirks and then you kind of build the universe up from there but all this research is suggesting that there is some degree of downward causal influence and ontologically it's actually quite philosophically difficult to like reckon with that I don't I don't know why that is yes I mean I wonder whether it's just a slightly different type of causation um from the kind of gluons or quarks up in sense that you know um going all the way back to Aristotle people talk about constraint versus causation and it might be that just C macro systems constrain the organization of micro system but yeah it's a massive question and yeah as you said it's very philosophically rich I mean strong emergence weak emergence all of this kind of stuff is exactly really philosophical excellent um going to sort of humans or are in silico simulations of humans or cognitive agents um when you put when you sort of run these in silico simulations you equip you know I read one of your papers you equip them with social information right social prior so in one of the your you had distance to the ne their neighbors or you would have the rates of the change of the distance I'm wondering whether would it be possible you know do individual agents need to be equipped with these social priors to become social agents or is there a way that actually just by acting and let's say having a shared goal but without actual reference to the presence of other agents we have this kind of gal or we have this kind of emergence of a overall pattern yeah definitely I I think so basically there's different ways you can effectively introduce correlations or coupling between agents um the way that we think I mean there's a lot of evidence that animals and agents in society do correlate each other's activity is through either directly or indirectly perceiving aspects of the other like we can see each other um schooling fish can sense their neighbors bacteria uh can sense each other in kind of like all sorts of uh interesting ways but there's nothing qualitatively saying that you can't couple um a a system of particles with some like third qut like uh driving or common source so for instance if I have a bunch of um particles trying to navigate towards a food source on some like media like they're all attracted by biochemical gradients towards a food source of course that will induce correlations in their activity so it will seem like they're all moving as one where as in fact there's nothing that's actually letting them sense each other but they're just some kind of common um Source that's giving the appearance of correlated activity and this like is a very uh this is a classic thing that comes up in Neuroscience too when we're looking at large recordings of neurons often times we're not rec in the whole brain right we're just looking at some small subsection of neural activity and you see all these correlations between uh neural firing patterns and you say oh look they're connected people use all kinds of correlational techniques to infer the the nature of those interactions oh this neuron is driving that neuron but you actually never know if there's some third um causal driving force that's actually responsible for correlating their activity and this is actually one of the nice things about studying Collective animal behavior like in the lab of um Ian cousin where I did my my PhD they have the ability to kind of track with High um resolution a bunch of individuals like every individual in an ensemble in a collective and they can even reconstruct kind of to some extent the visual fields and the sensory fields of the individuals in the group and in that way they can kind of decouple these potentially third correlating or confounding factors from the actual use of so social information that the individuals might be utilizing that's cool that's interesting um yeah because I can imagine without that it can be very confounded and it makes me think to what degree here is uh Collective Behavior genuinely advantageous for these organisms and I guess it comes to a kind of evolutionary question there is this evolutionary debate about what you know what is the what is the transmitted thing over Epoch is it the actual Gene the speci collective and so on exactly you know in some sense if we just say well there are these collect you know these aggregations of individuals which have similar goals and therefore look as if they are acting in accordance with one another and obviously when you start recognizing others well then you have to start taking them into account your work have you have you got any intuition as to whether the presence of others with shared goals is actually beneficial for the organism who's pursuing that individual goal or whether you know it'd be better if we were all siloed off and an island onto ourselves yeah yeah that's a that's like a really perennial question in the study of in not only Collective Behavior but like sociobiology kind of in its original formulation by like EO Wilson is you know is there something inherently advantageous to group living and um if so it's clearly not a be all end all because we do have the presence of species that are like solo Predators like wild cats right they're they're not living in herds but then there's other animals that are actually living in groups and so there's clearly some trade-off there so I think one answer that probably biologists because I have to admit like I often theorize very you know high level with Concepts from physics and Mathematics but there are clear you know individual Fitness and more selfish Gene related motivations for group living like a classic um one that has been used to motivate flocking and schooling fish is like predation risk if you're living in a group you're basically lowering the chance that any particular individual gets predated because and there's also interesting psychological effects that flocking has on Predators like there's a crowding effect so if there's a bunch of individuals in my visual field it's harder for me to focus on a single one that collectively lowers the predation risk of everyone in that collect yeah yeah yeah so that's one one answer to that there's another interesting um answer which I I I don't know this is maybe a little controversial and I think this is where it really ties into the free energy principle which is once you have a collective system regard regardless of whether it's actually beneficial to the individuals that partake in it if the system has dynamics that kind of allow it to survive it's kind of created now its own selection pressure on it in of itself so the system um simply by existing and not dissipating is kind of like self- evidencing or selecting itself at perhaps like a higher dynamical scale and this is where I think Concepts like the free energy principle which is really in the game of defining why things persist in the first place and what it means to be a thing um has something to say about about Collective Behavior so I would actually argue that there's certain um kind of group dynamics that exist sometimes even at the expense of individual Fitness but once you've entered into this macro scale the macro scale is kind of living and trying to find evidence for its own existence even if that goes back and punishes uh the individual actors that actually originally like Co operated to create it um that's a little bit more controversial but I think it's a really good maybe uh framework for understanding kind of like maladaptive group dynamics things like misinformation or virality social networks things like that well the Marxist will be screaming that you've got a great Theory there of capitalist you know capitalist realism yeah that's that's really interesting I mean I guess as a you know more philosophical bend on this one thing well where's the kind ofal of control here because I think intuitively we don't think that the group dynamics have control or agency like the overall Arc of a culture has the agency of its constituents individuals but this idea that there's like again I think it comes down to a kind of constraint causality distinction there are certain things that say that you can do within capitalist America versus what you could do in communist Russia MH and those actors constraints without there being some homunculus I mean obviously there are homunculus in in so far as there are political figures but no that's that's a really interesting point I think also what I've been thinking about is and this is a even deeper question is and I'm wondering whether you have to think about this when you talk about Collective behavior and aggregating individuals do you ever think at what point does one individual end and what and when does it be when how can we distinguish one individual from another and I know that sounds stupid because like people would just say well it's the body and and you just have it you just see them and obviously when we're talking about high level evolved systems like the visual system then it probably is based on you know V1 picking out lines which distinguish indiv uh you know um individual organisms I'm curious in terms of the actual basian mechanics and the free energy principle is there anything that gives us individuated thingness Beyond taking that as a kind of axium like oh no there it just is a thing that is self- evidencing no yeah I I don't think it does I think that's one of the challenges of maybe what the general problem would be called is like system identification or Markov blanket identification how do I like look at some high-dimensional system and actually pick out what are the individuals or the components of that system and even within um like bi biological systems it's often not uh that clear like you and me might look at uh Hill of termites or ants colony of ants and say okay yeah those individual ants are the individuals but in a system where they all share the same genetic material it becomes a little bit unclear and and especially when you have these kind of self- ulating sacrifices for the good of the collective it's you start thinking about things like the extended phenotype like are these individuals actually individuals or are they kind of just manifestations of some common gene pool they're kind of like the the tools and the fingers that the pool is using to act in the world um so I don't think that basing mechanics has any like strict definition about what a thing has to be I mean people will disagree with me on this like for instance the recent work from um people like Carl friston uh on on particular things strange kinds the this line of papers actually makes particular arguments about what cons what constitutes a thing and it has to do with a particular set of dynamical con straints between the different subsets of a thing like there's active States and sensory States and there's certain conditional Independence relations that have have to exist um so so the proposals have been made but I don't think anything about basy mechanics actually tells you how to do the partitioning of the state space it's like given a state space we can then start interpreting the Dynamics of that thing as doing some sort of basian inference but where the actual State space comes from that's a much deeper question that I think is like an active active area of inquiry that's really yeah that's fascinating because I guess one way of doing it would be that you well you act like scientist in some way and you go well if these things are behaving differently let's say you got two ants that are behaving differently they're diverging in their movements then you would say well we can make the assumption that their active and sensory states are different their Mark or blanket is different but if they're replicating one another then you know that all even that uh decomposition of the system in of sensory States and active States kind of kind of informs you to say that that's one overarching thing and again I mean I like recruiting kind of a philosophical vagueness here which is that like from a philosophical perspective it's probably just an empty question and there is you know it's it's well what point does a pile of sand become a heap or you know and so on and it's it's empty if not if not interesting and maybe beneficial when we're talking about well I think there are phenomenological effects about you know to what what degree do I recognize myself as a kind of siloed off individual versus part of a group and there are probably very aberant ends to that Spectrum like social isolation versus schizophrenia where I'm kind of melting into the world versus being completely alone so I think there are there's import but yeah I recognize that it's yeah I I do think yeah I I I totally agree on a philosophical level it affective there is no hard line in the same there's not going to be some be all end all definition effect like event what will be our deciding factor is the utility or like I guess more pragmatist sort of stance is like the partition we choose for a particular system is it going to help us do something so for instance in a lot of my um interest in Collective animal behavior I I've just been mesmerized by like videos of schooling fish right and these schooling these schools are not like cells in the sense that you know the the I mean cells potentially violate this as well but the position and the role that individuals play Within the school are not fixed right so fish can like go to different sides of the school some fish can kind of act as the eyes and ears of the school While others are acting more like the leaders so you have like spontaneous change in roles and Leadership and that already is basically telling you that at the higher level at least the the kind of sensory states are not assigned like unchanging individual identities so there so already the partition we use if we want to start studying the the school as an individual that partition has to kind of supersede individual identity has to be some spaciotemporal course graining of like the movements and identities of different fish or particles over time and which partition we use should be a function of like what question or what hypothesis we're trying to answer yeah so it comes down to this theological or pragmatic motivation have you got this is seems like a much more bow question but I'm just curious because I don't know that much about Collective behavior and bi have you got a particular favorite of collective Behavior you mentioned schools of fish is there anything else that kind of stands out as impressive yeah I so schools of fish is probably my my top one just because they're visually so mesmerizing I mean Starling flocks are are quite interesting as well um particularly because so it often happens that in many realistic schooling scenarios although you'll have three dimensional schools this is something I I learned from my my adviser Ian in practice a lot of the school actually is happening in two Dimensions so even threedimensional schools are actually made up of more like 2D manifolds whereas if you look at Starling flocks they have very interesting three-dimensional structure so you've probably seen these like um what they call murmurations like these kind of shimmering and they almost look like chaotic like strange attractors the way F over on themselves and even those have like quasi two-dimensional structure but they are they're those two dimensional planes are moving in 3D space and so stuff like that is just visually very interesting and there's a lot of really interesting um research like trying to do high resolution recording in 3D of all the birds in a in a flock and trying to track them so I think that's a really a beautiful one but again it comes like it comes back to your earlier question is what is the actual function of that some sometimes these murmurations are very beautiful and like impressive but people still don't really know like what the function of like such crazy displays of collective coordination are yeah it bring it it brings to mind what you mentioned about the fact that there are this actually conversation I had with KL because we were right at the you know the first episode of this podcast we were talking about what is the imperative Cole you know originally spoke about an existential imperative underlying the free energy principle but it's a slightly misleading term because it doesn't say that you know we have to do anything right I could just disintegrate right now it's saying that if I do persist then I look as if I am doing variational Bas inflence so on so I said to myself well but is there an underlying tell us to you know is there an evolutionary pressure to survive right this is just a kind of a biological self truth and he went yeah and and you kind of see that because there are not many animals that kill themselves right like there there does seem to be some underlying pressure or some self- evidencing survival in a way like survival is self- evidencing but it does bring to mind this really interesting fact that there are some animals who will self imilate um and I yeah I think that is so interesting um is there is there any kind of idea about Beyond you know you we mentioned ants and termites and I think that's kind of altruism for the group um are there any other examples that well I'm wondering if there's any examples that might just F be very tricky to explain under a kind of Basia mechanics or under an act of inference I mean and we can expand that question more broadly and just say is there any an Collective behavior that you just find staggeringly odd under like an embed markof blanket system yeah I mean I I think like so one of the the main reasons I went into the collective Motion in particular like the schooling fish and the and kind of flocking birds was because I found them to be exactly those examples that violate the kind of classic image we have of marov blankets where you have like kind of layers of states that are not really changing like you have the particles on the edge of the blanket and then you have the ones that are a little more inside and then finally you have the kind of hard nucleus of States yeah um so I find that even like basic Collective motion um kind of evades uh proper understanding under the current iterations of basy mechanics I mean this is part of the reason the paper you mentioned that kind of studies uh like frames individual elements of like a school as like active inference agents that that paper actually didn't try to formulate the whole school as a collective that was one of the other objectives I had during my PhD and it's something I'd still like to to study if I have time but um I found that actually doing proper basing mechanics on the whole school as if the school is the unit of analysis was quite difficult precisely because Collective motion is an example where the roles that individuals play um is changing dynamically so if we are to find like a stable marov blanket description that satisfies all the tenants of the free energy principle we will have to kind of come up with a more Dynamic um version of system identification that allows you to kind of uh dynamically redraw who is a sensory State what parts of your high-dimensional state space are playing the role of active versus sensory versus internal dynamically over time so I think even like the most kind of basic examples ant Colones as well right they're Dynamic mixing system although the roles are more genetically predetermined for social insects all these examples I think are are a bit of a challenge to the classic formulation of basy mechanics um right well I guess one of the earlier critiques of active inference was that it's a kind of state based um Sy you know formalism which doesn't allow for kind of dynamic change as you say and over ESS and I recognize I think this is something that actually came up in a odd Twitter discussion between Maxwell and Kate Nave about um path integrals and the path Dynamics it might be you know you're right at the Forefront of This research maybe it's worth just for the audience unpicking what is the difference between a kind of state based or static active inference versus a path-based active inference which allows for this kind of well I you know think of metamorphosizing Mark of blankets or something like that yeah yeah for sure so the the classic um variant of deriving the free energy principle rests on specifying like a what's called a steady St distribution so it's actually just a probability distribution over the states of the system that should not change um and this is you know this can generally be applied to many systems at least on some time scale like so it seems like the distribution of particles in a rock or me and you for example doesn't seem to change on quite so long of a time scale of course the rub is in how do I Define what a state is is a state of particular cell because cells are turning over all the time or is it maybe tissue things like that but anyway the the basic um free energy Principle as it was I mean I I guess as it was pedagogically described this is I'm referring to papers like the free energy principle for a particular physics the monograph from 2019 so the idea is you you have this stationary distribution Over States and and it's a like very trivially a multivariate system so there's a potential for some of those states to be active States sensory States internal States you've kind of partition the system but what's important is that over a long times if I measure the system the probability distribution of being in this part of State space or this part of State space that probability is fixed it doesn't change over time so it still allows for particles to move around if I look at the individual trajectories like things can change there can be fluctuations but the stationary density the probabilities are are constant yeah that's in contrast with the more recent path integral or path form where it's not the distribution over um the states themselves like finding my position in this part of the room at over time on average but it's more a probability distribution over paths or trajectories themselves so the point of this is that um there's also a stationary measure or a stationary distribution but it's not over particular points in state space but it's rather over sequences of points Y and that allows you to have a lot more flexibility in the Dynamics where you can have things that appear non-stationary in the sense of if I look at just the positions of the variables that will be changing over time but it's because there's actually a more like abstract stationary measure which is operating on the paths or the sequences of variables of the system um so yeah this is what allows I mean apparently this is I think what's going to be upcoming as we see this formulation unpacked more especially in terms of simulations we're going to see versions of this basing mechanics applied to systems that are moving in time and not stationary and this is only something you can get with the path-based formulation so when you talk about the states uh so we're either talking about the source of path that states take or the kind of position that they have at a given time what part of the mark of blanket are we talking here because some people talk about the internal States uh you know parametrizing beliefs over external states and they self- evidencing and then some people talk about the actual blanket States or the par or some people blanket States reducing VF or so people talk about the particular states which is the blanket States plus the internal States so when we're talking about States uh tending towards an attracting set what what what what are the commitments that we're making here in terms of which states those are so yeah people will disagree on this I mean in the original formulation of the free energy principle it should be all of those things yeah so blanket sensory active and internal all have a stationary distribution defined over them right so so it's basically the joint distribution of all the subsets of States that's the thing that should be unchanging is that including would that include the external States or we're allowing those to have some non you know chaotic element to them yeah I mean for the mathematics in the original formulation to work you actually also need the external states to be unchanging which is one of the critiques that the enry principle had got is like you're not really defining a stationary system to be the system per se like the agent but you're actually including the whole world yeah yeah agent is embedded in as part of your stationary measure and you know you could make arguments that oh well it's um you know referring to just the Eco Niche like the behaviorally relevant part of the agent's world that it's trying to control so it's kind of like the agent is forcing its external states to to obey the stationary measure um but I think the path-based for foration allows you to get around that because all these things now become nonstationary if considered in terms of just raw States but but yeah it originally it does include all all the subsets of States but it sounds like even when we're talking about the change of uh the path of states there still seems to be some kind of predetermined characteristics or predetermined attracting set such that path is tending towards a certain probability for sure so you're allow for some what Carl would call sort of itinerancy or you know some deviation from that ideal but you still got some pre- caracteristic uh Dynamics I'm just wondering you know you'll know a lot more about physics than I do how much does that really square with kind of fundamental physics or our understanding of the world like is it is it actually feasible to say even if we allow for some itinerancy and change over time there are there's like a mathematical way that you could still describe that yeah I I think it that actually that assumption is quite consistent with physics because I mean there there's a lot of like uh equivalency between these different things so as soon as I say oh these stochastic differential equations tend toward some attracting set another way of saying that is I've just written down a particular form of their flow like the way that they change over time some particular equations of motion yeah and if those equations of motion meet a few basic constraints like one of them is that they don't diverge infinite into positive or negative Infinity which is like I think a a pretty safe assumption I mean if we if we're assuming all of our equations diverges to Infinity we wouldn't be able to do much with them so as long as you say that this equation doesn't diverge to Infinity another way of saying that is there is some measure that this belongs to it basically will tend towards something with constant probabilities and those constant probabilities in in certain systems will be better um described in terms of paths rather than States so like the paths of the system will have constant probability so although that sounds like restricting it's actually it's actually just a statement of writing down any differential equation that doesn't have some crazy like kind of impossible form right yeah okay final question on the physics uh because you did a reply to this how particular is the physics of the free energy principle Pap by aguera and colleagues and I just was really curious because it it's very much pertains to what I was saying about what states are we talking about the particular States the internal States the blanket States and you say in that paper and I can quote I express General agreement with the target article statement that the marginal flow of internal states does not point along variational free energy gradients evaluated the most likely internal State however in this commentary I focus on the flow of particular States intern brackets internal and blanket states and their variational free energy gradients and the average flow of these systems do point along variational free energy gradients and in my notes I've literally just written what does this mean yeah no thanks for bringing that up because that I I wrote another commentary I think on the same article that was a lot more like it was more about this sparse coupling conjecture and that one actually didn't get much attention but so yeah that effectively this is a very interesting point because the the one of the main hypotheses of the free energy principle and this manifests in terms of like particular process theories like predictive coding is that if you look at the internal states of some system they're pointing directly towards the free energy minimum so either on average or if it's deterministic for a particular path the system looks like it's minimizing free energy very nicely so in the same way we train deep neural networks to exactly maximize the ability to predict the test data we train predictive coding networks to exactly minimize free energy so they're taking like the direction of steepest descent towards the free energy minimum and at that minimum is where your inference is best you're at the local minimum of the free energy your inference over external States is the best it can be given your approximate exterior in your generative model so what Agera at all's um paper found is that if you look at like very simple stochastic differential equations these are like uh in this class of linear system so they're very easy to analy and they're probably not the best model of the more complex systems we're actually interested in in biology but they're a really good starting point what they found is that sorry sorry got to walk um uh that they found that even for these simple linear systems the average internal states are actually not pointing towards these free energy minimum and that was kind of posed as like a challenge to the free energy principle and the the mathematics behind that derivation in my opinion were uh totally sound so it is true that actually even in these uh very simple linear diffusion systems you don't get this kind of nice interpretation as internal States walking in the steepest direction towards the best inference they're actually taking a more circuitous route towards the minimum which entails the best inference however if you extend your um your kind of your your definition of internal states to include also the active States and the sensory States so the part so-called particular States the things that differentiate the particle from the external environment then those things actually are pointing down free energy gradients and this kind of is in line with this general idea that I think is a lot more in line with like the idea of sensory motor coupling it's not just the internal states that are doing inference but the internal states are kind of cooperating or conspiring with your active States in order to collaboratively get to that free energy minimum at which point inference is exact or as exact as it can be given your approximations so it's saying okay I don't need to go the the steepest way to the free energy minimum I can take like a kind of curvy circuitous route but I'm at the same time I'm pushing my active and sensory States in such a way that will actually minimize the time it takes us to get to the free energy minimum and that was kind of the point of that um of that article or one of the points no that's really useful I'm just wondering um so when we talk about so we're talking here about the sort of self- evidencing or the gradient Descent of particular States um should we is could we say that actually it might what would it make okay what would it mean to say what would it mean what would it look like if I said we're doing gradient descent just on blanket States so let's just ignore Silo off the internal States for a second and just say are blanket States absent the internal States also do they Al Point down variational free energy gradients yeah I don't think that is guaranteed actually I don't think blanket states are are necessarily pointing down um free energy gradients necessarily without taking into account sensory and uh or sorry uh internal States so the internal states are kind of the things that are driving the active states to jointly minimize the free energy and the free energy recall is defined on both the blanket and the internal States because it's defined on the observation which are like the blanket States and it's also defined on your beliefs over external states which in this case are parameterized by internal States so if you define the the free energy just on the blanket States I don't think it's guaranteed to it will be minimized in the long run but it's not guaranteed that the Dynamics are pointing in the direction of steepest descent how do you when people so I think people this is kind of coming to the kind of education of Act of influence I guess and and part of this podcast is me learning and the audience learning alongside with me when people when people like you talk about internal States I understand what it means to sort of parameterize ex uh beliefs over external States and in some ways you're doing vfe because you want to return to like a set of external states which is viable for your existence so fish are not going to be found outside water or I'm not going to be found in an ice cube so on Ice Cube freezer I don't know um now my sort of persistent question I've always had and I don't think anyone has really answered and I'm not sure there is an answer is is that we say that the internal states are kind of the vehicle for these beliefs but are they could you also just say they are these beliefs like is there anything over and above the internal States Beyond these basian beliefs yeah no that's a really good question so this is this this gets into a bigger question also about identifiability and uniqueness of the free energy principle and basy mechanic so Bas in short the the internal states are not just simply the beliefs because they are whatever physically they are like if if we're looking at a school of fish and we're saying these five fish are playing the role of the internal States or looking at a cell this part of DNA is is playing the role of the internal States it's coding the the um production of proteins that itself that internal State doesn't have anything intrinsically it's not parameterizing parameters of probability distributions over external States so what's always at play when you're saying that the internal states are about or some in somehow representing external States is there's always a function there which in the classic free energy literature is called the synchronization map and what this is is it's a function that takes your internal States and it Maps them into the parameters of probability distributions so if I want it's basically something that takes the raw like dirty physics of the system however it is it's like you know the metals and the ions and the the the things that actually consist of your system and it's mapping them into a space of probability distribution so if we wanted to say that um my neurons are encoding beliefs about the position of objects in the room what that that function that synchronization map would be doing is it would like take the firing rate of a neuron which is like an actual physical neurophysiological property that I can measure from the neuron and it's mapping it to something like the mean of a gaan distribution or the variance of a gaussian distribution so I mean I guess in that sense it's like do you think that the firing rates of the neuron simply are the belief I would say that and actually this this kind of hints at at something I I um saw you talking about Alex kefir on on one of your earlier podcasts is like this kind of identity problem like are the neural firing rates the belief the representation themselves or is there some map that takes the physics of the system and then Maps it into a probability distribution into a representation so I think you always do need that function that actually takes the system and Maps it to a belief but the problem with identifiability is it seems like there may be many candidate functions that take this the system States and map them to a probability distribution over beliefs so it's very hard to just look at a system and say oh yeah it's forming beliefs about like the average distance to neighbors or the the light refraction in the room or the contrast of some some image out there we we usually come to the table with very strong priors about for instance neural coding we think that neurons either code things with the timing of spikes or they use like the firing rate and that's how they do the encoding and that's basically saying we come to the table with priors about what that function is but in theory there's nothing about the free energy principle that tells you what that function is so it's a very hard like identifiability problem in general okay that's interesting yeah I mean another thing that kind of sticks in my mind when I think about this is where does the where do like where do the beliefs stop so what point is something internal to the system and what point is something external to the system so um like for example let's say my I right there's something like me let's take as a kind of presupposition I am conducting variational basan inference like over the external States but the external States in some strange way are also myself right because they're also let's say the observations that come with respect to my glucose levels now that's because I need to have some beliefs right some probability distribution that my glucose levels are going to tend towards a certain point in that like there is some internal belief about an external state but that external state is actually still within me I we get we kind of get around this through this notion of embedded Marco blankets right like I'm not actually parametrizing those beliefs but actually my CES are but I guess the point here is is it we it comes back to a question that I've had loads of times and people have had different answers to it is this just a useful structuring tool here where I can just say well I don't really know why or how or when this Mark of blanket ends and becomes part of a bigger order Mark of blanket and so on until you get something that it's like to be me but it's useful and we can do useful maths or useful physics based on it because I just think like again it's philosophically vague as to does it make like is the cell is it part of the you know is there just a straight allision really between an internal State and an external state from the perspective of a cell because it seems that it's also doing basian beliefs on its own location its own status its own right like so I've always struggled with that with the free energy principle yet it makes sense for me that the internal States I have to parameterizing beliefs about where I am in the world or who I'm with and so on but what about like what about myself I've got to be about my glucose levels my temperature my well-being and all the way down to my like very granular physics level yeah where does it stop yeah exactly I I think the generic answer to this I think is basically what you meant by embedded Markov blankets which is if I if I look at like a coar grain level like more a psychological level of explanation like you you have beliefs about who's in the other room or what's behind your door so that itself could be drawn out as like a basian network where you have some sensory states which are like your sensory organs like your eyes and ears and nose and then you have your internal state which is like your psychological state or something or some coar grin representation of what your brain is thinking and then you have that external state which is like the presence or absence of another person each of those nodes in our basing graph we can kind of double click on and like zoom in and that itself is a a a a thing that has internal blanket sensory so that's like the generic answer that that um people like Carl frisen will talk about with the renormalization group like you have marov blankets at different scales and of course the work of Maxwell ramstead and people like that who are literally like writing papers about how exactly this happens you have this nested markup blanket so I think that is the the general answer is that every time we write down a basian Network and a graph we're like saying okay that's the blankets that's the internal that's the external every time we do that we're kind of admitting well actually I can always like take what I consider a single state and just rip it up and like start partitioning that right and then I think the the ultimate conclusion of that exercise is basically your conclusion which is it all becomes a matter of why are we doing this like why am why am I at this level of zoomed outness and is probably for some practical utility as a modeler as a neuroscientist as a physicist yeah yeah so if we take the sort of psychological perspective and let's say you know so let's say you actually will use your uh preprint so the paper that I was mentioning before was from the um I believe it's Collective behavior from surprise minimization so that's a really great preprint that people can check out is obviously quite technical but there's again lots of things that people can get out of it um let's say you know we embed these we're doing these um basian belief over the distance that I am from another person and the rate of change of that distance I guess my question here is am I also conducting basing beliefs about where I am do I get where I am out of just like do I get where I am just out of the beliefs about where other people are even at very psychological level you know there's someone else in the other room do I also need to be doing basian beliefs about myself in relation to those external world and does that mean that I am also in some ways like I've got a jeel perspective I've got like this jeal monism where I am doing the basian belief about myself as if I was part of exteral world yeah kind of like doing doing theory of mind on your own self having to simulate your own inference process yeah I mean so I think the argument made in that Collective behavior from Surprise minimization paper is that um you can get away without that very like you can get away with a lot of coordinated Behavior where agents are tuning their own position and their velocity and space just by operating on very low-level reflex arcs basically just trying to minimize sensory prediction error and so those agents in that paper don't have any representation of their own position that's not like a latent variable in their generative model all they do is they have some velocity vector and that induces prediction errors and what they can do is they can just change that velocity to basically reduce prediction errors so you can get a get quite a lot of sophisticated Behavior without that representation however I think there are plenty of good examples of systems and maybe this gets more into like what you would call metacognition although it doesn't even have to be that but there are systems where you would like to have a representation of a random variable in your system that represents something like the self position y um and and you would like to do inference over that variable and that basically is what active inferences if I have a a variable that corresponds to some latent that can control my own body position or my speech or whatever and doing inference over that latent variable is basically what ends up being some kind of agency or control and I think the Reas the cases when you would want to have that extra variable are ones where the Dynamics of yourself are are above and beyond what can just be determined from your sensory inputs so for like these reflexive fish I can get away without having a self variable because their behavior is pretty much completely a deterministic function of their sensory states there is a little bit of like memory in there because they have the belief from the last time step of belief updating but it's very simple it's not like a very complex dependency when you have individual um agents that have a lot of like autonomy I guess which I would just parse into like more long-term nonlinear Dynamics then it makes sense to introduce another latent variable in your model that corresponds to something like myself or my position or my actions and at that point you're going to get more of like a I would say a tension between externally driven um behaviors that are driven by sensory stimul only and internal more like endogenous or autonomous behaviors and that's that those are the cases when you would want to put that latent variable in there yeah I've been I've been thinking about this myself we're just finishing up these edits for this flow States paper and um trying to explain sort of with lar and Carl and and others and trying to explain sort of what it means for the you know this the self is the so-called s hid like one of just many hidden causes according to act of inference is hypothesis cause and trying to explain kind of the difference between an internal cause and an external cause for something that's already presumably internal right like me and um yeah totally this is cool though it's uh yeah I I think I remember hearing may you you're probably more up to date with this but I remember hearing Carl talk about like the idea that the the very fact that we introduced something like a self was basically a new structure in a generative model um in order to explain disparate input so it's like I'm hearing a bunch of speech signals and if I don't if I only have one latent variable in my model which is like there is somebody speaking right then it's not going to be a good enough model of like the speech signals and when you get enough of these like social signals it actually becomes the free energy minimizing solution to break that node into two and there's one that I can control and there's one that's someone else that I can't control and that's the best way to like explain the data well yeah and presumably this is happening actually in developmental psychology and developmental biology whereby a child doesn't really know have a self other distinction and I I always relate this back to I think action is very important so this is going back to the work of someone like Chris fiff and uh the comparator model whereby I can make predictions about the consequences of my action and the Very fact that I can do that and witness the sensory outcomes of my action means I kind of get well I get this sensory motor Arc and therefore I can have a higher order inference that there is something that that internal to my generative model that is driving that action I guess the question here is what's happening in something like a Psychopathology like for insertion in schizophrenia where people don't trust that the thoughts that I mean I think this is actually kind of true and I think the Buddhists actually flesh this out quite well that obviously if you actually meditate you'll see that well the thoughts are not yours like they're not cut they're not you're not making the thoughts but there's a classic thing in schizophrenia of like people who are schizophrenia will often think that the thoughts that they're thinking aren't theirs they're being beamed in by an alien or a government surveillance operation and how you feed in something like a predictive model into that unless you take f as an action and then say well I'm predicting the outcomes of my thought and so on that becomes tricky because I guess we think of predictions as thoughts in some realist way and so you end up with this circular Loop but yeah it's um I think it's yeah it is fascinating I think it's a I think it's a I think this idea of the self as an inferred cause is reasonable I think the only problem is is that it engender some kind of H potential homunculus which is sort what's doing the inference in the first place yeah exactly um but these are these are questions for yeah that brings you back to having to Define internal States like what the internal States or the self and you're inferring that that's even exists you need to define the inference process on some other subset of States like that's get ground in the first place yeah exactly yeah cool uh well you've just given me another paper idea and maybe a PhD idea um so okay awesome I wanted to ask about this scene construction paper because I've been really interested in scene construction and I was I was happy you know I I saw you work with bet mitzer and I think his work is really amazing uh and I just wrote his paper on attention and it's super inspired by what he was doing with Carl and this especially their selective attention paper the 2019 paper yeah definitely yeah maybe just for the audience who aren't who probably have a idea and intuition what scene construction is and they probably think of it as visual although I really like the sort of language example here maybe yeah you could explain just very s of high level what scene construction is yeah no I like that you brought up the language example because that that's actually what originally compelled me even when I saw those papers on scene construction I actually immediately thought of it in terms of like parsing and language a scene construction is just kind of a a type of hidden variable inference so I have a bunch of sparsely sampled data points and then given that sequence of data points like little sensory samples I suddenly kind of infer something that's explaining all of them at once like oh this this is the latent cause this is the latent exp explanation that kind of unifies all these disperate um these disperate data points and I guess the construction aspect comes from two ways one is the fact that usually the way we get that sequence of sparse data is through some kind of sampling so like as I read a sentence I I'm typ in in like Western languages you're typically reading left to right as my eyes go right across the page I'm gathering more evidence and I'm constructing the scene as in my posterior probability distribution over these different explanations is kind of shifting until at some point and often we see with human language and visual understanding there's kind of this like nonlinear feedback where oh it it kind of snaps into place oh this is what's going on and it's very interesting seeing this in language too like in different languages like German for instance the verb will come at the end of the sentence so you kind of have to wait until the end of the sentence before that meaning kind of snaps into place so that that's generally what I would describe as scene construction and then in the visual case often it's um you might be looking at a a uh a painting or something like an ambiguous painting let's say some a modernist maybe abstract thing with not very clear figures and you're sparsely sampling it with your eyes trying to figure out like what what's actually going on here and at some point when sampling you you get that just stal impression of oh there's like a a figure in a cloak or something and that that moment of gal recognition is like the the act of constructing the scene of inferring the latent explan for all the sensory data that I've that I've gathered excellent that's really useful I guess something that Beck's work really drove home to me and impelled me to write this paper was the importance of context so if you're doing a sort of Yus task um where you have a PCT exactly what you just said you have a picture and then someone says well how rich are the family in this picture and then you scan all of the furniture and you look at their clothes and then they they are something else like I don't know I I don't actually know what it is but you know let's say how well do they get along with each other and you look at how they're sitting and you look at whe they're looking at each other so context is clearly driving a kind of overall uh the the the kind of derivation of a latent C in some ways because you're going okay well I'm going to pick out this evidence and that's going to drive my inference so are we would you say that we're always integrating a kind of higher order context when we're doing scene construction such that you know there is no such thing as the kind of neutral scene um it's always you know the inference is always being driven by our recognition of where we are what we are and so on totally yeah I think that's that that's one of the most interesting aspects of basian modeling in general is like the the the ability for people to very rapidly infer a context which in in to map it back to the the kind of abstraction I used to describe scene Construction in the beginning is like you're inferring which latent explanation you're even testing yeah exactly the cas of um you get the sense that the family in in the painting is Rich you're suddenly that's inference of a rapid context that then induces which latent explanations am I interested in learning about right like Rich versus not rich whereas if it if the um the cue or the prompt was is the man wearing a red shirt then the different latent explanations that you've suddenly inferred you have to test is a different set yeah I think that's like one of the most amazing and and kind of underexplored abilities that humans and other animals have is they can in they can use context to basically quickly infer a generative model so like the context kind of selects the generative model that then you use to do something like active inference Yeah well yeah I've been thinking about this um because clearly clearly it's it's just not computationally feasible to uh contemplate or assess every possible State I mean this is the basis of variational basing inference is that kind of P of Y is just it's in almost infinitely diverse in its state space and so I've been kind of proposing that there's a higher order action policy which does the kind of pruning um to use reinforcement language the kind of pruning of your potential State space and i' be thinking about that a lot in terms of action because even action like you can't I don't consider doing absolutely everything at any given time have you got any other like fur intuitions about how that might work because I think the slight the slight tricky thing here is that we have a kind of higher order policy let's say to prune our state space but that needs itself to be driven by observation right I need to know okay I'm going to prune accordingly because I've observed something in the world right like so I see that it's raining for example in London right now and so like I'm just immediately pruning swimming trunks and sunglasses and so on but I needed to do that observation in the first place so it sounds like I got have to hire order the action policy to observe the world to drive my context I'm just curious about how much how How Deeply recursive does that go yeah I I think like the the overall my I mean I would like to think that there's a generic solution where you basically can start with no structure and like build everything from scratch but I think there's basically no free lunch here even and I agree with you that like maybe the best way to explain human behavior is that you're inferring a or inferring um something that then allows you to prune or select a model that then you can use in practice but the process by which you do that also assumes some kind of model like what's the model by which you infer I need to act to do this where those models come from these like deep hyper priors about the spaces of models that I can select at at like a lower level those are probably things that are developmentally inborn those are that's probably the space that like Evolution actually works on like on the space of kind of hyper priors or deep hyper models that like babies are born within their brain and these things are are probably things that you and I couldn't elucidate in like like in in human cognitive neurosciences like a probability of the dots moving right versus left like that's a likelihood we can write down these kinds of models that are like the models about how do I select which structures to use for a given task those are probably very hard to put into words but those are the sorts of things that I expect developmental psychologists have somewhat of a hold on like these they probably have to do with like intuitive folk physics like things like there there are objects there are agents there are things with like spacio temporal correlations over time like very deep physical constructs but um but I do I do think that at a More mechanistic Level what you're saying makes a lot of sense I I think like one way you could formulate this is in terms of mixture models so mixture models is like I have some assignment variable that's very high up that tells me which model am I using right now and so the mixing variable is what you infer and then given the inference of the mixing variable that effectively selects one of five or 10 or a thousand different alternative explanations for the data and usually those are form are are models of the same form like a gaussian mixture model is a mixture of gaussians but I think in what you're discussing what you're mixing are like totally alternative structures like one structure that I'm inferring one context I'm inferring I'm in is like I'm driving a race car another context is that I'm talking to a friend or a colleague and those are totally different models um I think one place where the mixture model falls apart is with mixture models you would assume that when you infer that higher level assignment sometimes that inference can kind of be wide so you're not sure what context you're in but when you look at human behavior people tend not to mix context there's some experimental paradigms where you get that but often people infer like they kind of Select like I'm definitely going to make these assumptions going forward I'm definitely going to make these so there might be something like a better model of structure selection than mixture models but that would be one idea I think like mathematically where to get started would to be looking at like mixtures of structures effectively yeah yeah yeah nice I I spoke to sanjie now Joshi about this on the podcast who's versus with you and yesterday I spoke to him about it and we went back and forth and I think we ended up grounding out in evolution so I think you're absolutely you're absolutely right I think yeah there are a couple of things I want to say to that one is it's always I tell everyone this on this podcast and personally that I think it's always a bit dangerous to just take one slice of the generative model at one slice of time and take that to be what's actually happening it's always Dynamic your observations are always feeding into the upper levels which are feeding back down I guess that's the beauty of a kind of predictive coding or a deep parametric modeling system is that like this is just an idealization it's it's it's constantly happenings um I think the other like point of uh complexity here is that not only uh do we need to let's say derive a context we also have to derive the salience of a context or like the relevance of a context so you know I've been yeah I wrote this paper where I'm kind of talking about the circular causality between preferences and attention and something that I kind of realized was well and well I knew it obviously because it's just for my life that if I'm hungry like if I'm truly starving I'm not I don't care about anything else that's on like that seems fundamentally peripheral at that time whether that's finishing a paper or you know being on my phone and so on which means that like there's almost not only is there a higher order policy that I prune my state space according to the fact that I'm now hungry but also that now trumps any other state possible State space like I'm on my phone or I'm riding my S which implies that there's like an even higher level Precision waiting policy that says well not only do you have to prune accordingly but you also have to prune in a hierarchical fashion yeah and I don't know again I don't know how deep this goes because as Carl will tell us anatomically the brain is very ridy and very recursive yeah that's true no that I mean that also reminds me I think of this paper of Burks that you mentioned from 2019 right because if I remember correctly that version of selective attention depended on the preferences is that right so yeah that that's something like other than other than that work by Burke and I guess the paper you're discussing now I don't know of much work that explicitly uses the preferences to then select what generative model is being used for inference because you're absolutely right it's not just oh I have some observations then I infer the context which then tells me how to act but that inference also depends on like what your goals are like what is important right now and usually we get importance in the kind of classic modelbased reinforcement learning way is we we roll out a given policy and we see how much does that policy overlap with what I want like a reward function you basically evaluate policies in terms of reward functions but what you're suggesting maybe cannot be accommodated in that way where the actual inference itself is biased by it's not just policy selection but even State selection or state inference is biased by what's important what's relevant um and I think you there are ways you can get that like there's this um generalized free energy paper by Thomas par and Carl frisen from 2019 where they show that in that in that particular formulation of variational free energy called the generalized free energy you actually do get this interesting influence on state inference from preferences so your preferences will kind of optimistically bias your state inference so that you'll only be doing inference about things that kind of matter for your action selection so that might be one one place to card pointed me in the direction of that paper because he read it he read my paper and then obviously didn't tell me about this one that sounds absolutely right yeah because I mean my way of coming at it was thinking well in principle you know there's near infinite things that I can optimize my free energy minimization over right like I and there are ways out of this I mean some people will talk about something like uh you know Julian Kine or Mark Miller or Mark Anderson was about aerodynamics so it's not enough just to minimize free energy that needs to be a constantly improving slope of prediction error minimization but I still don't think that does it because in principle uh I could just get way better at tidying my room but like that's just or or something extremely trivial yeah that's going to cut it ultimately because I might just end up starving so it's yeah is exactly as you said um I I still think this can be couched in terms of something like an expected free energy function it's just it's just far it's just higher order and everything trickles down from it such that as you say like now we have like a selected generative model in truth I haven't thought too much about how this could be implemented mathematically because yeah you know that's the place that that because that is yeah that's totally true you could actually say because because the typical way we do the expected free energy is in like this Brute Force enumeration like let's say I did this I did X versus y if I did x what would my expected free energy look like it would be combination of the utility which is like the preferences and then this info Information Gain if you were to evaluate that Brute Force for like model selection like if I was to select this model and then go through a whole round of active inflence with this model it just becomes very hard to compute the expected free energy I think so maybe there's just a better algorithm or implementation that would allow you to kind of heris evaluate these counterfactual consequences of like if I selected this model what would my would that make me less hungry would that like Sate me um but you probably have to come up with some huris or some clever way to to get around the enumeration well I wonder whether it could just be belief free whether you might just like we might just have contextually cued model selection that you know the moment that I have the slight you know the slightest drop in my glucose then the whole thing Cascades down such that I have the prioritization of seeking food and I I don't even have to run the expected free energy of I could go here I could go there I could go and and what am I you know how well am I going to do yeah rather I just have this one now I just at the very bottom of all that process I just have this one preference which is eat and I think you know something like that might uh hijack or or shortcut the whole process leading to like quite low compute but actually a pretty robust um way of like getting adaptation because presumably this is something similar to what a child is doing right like yeah and and I think that kind of works in terms of like I don't know like the Simplicity of children in some way is that they they sort of cry over anything which kind of implies that there is just like a very simple stimulus response mapping and I wonder whether that could just be expanded you know just more broadly to model selection absolutely yeah I think that ultimately is probably what's really happening in biology because this is this also extends across the the bi ological um Spectrum like animals are very context or like basically need driven like things like attention all these basic cognitive faculties are really enslaved to effectively the basic things that the the the lower brain is telling the body it needs to do like breathing eating um thirst sleeping so I think ultimately it is some fast stimulus response mapping I think the only issue with that is it does kind of it it it seems less princip right it seems like oh we just have to hack in a short circuit and it's not it's not just like evolving through a neat process of free energy minimization maybe it is but it's just happening on a slower time scale right like it's some slow accumulation of experience evolutionarily that has trained this short circuit inference to say I'm hungry yeah there might have been some EF calculation on the part of evolution to select for yeah you know uh stimulus response mappings for something very like fundamental like food or sleep or breathing and so on yeah exactly yeah okay cool well that that's given me lots of ideas I need to think about um nice Yeah final sort of topic I want to touch on is you know just before we went live we spoke a little bit about you being at versus uh full time and I I I wanted to sort of ask again I know between the sanjie and others that everything is very under the wraps and I and I respect that and I don't want Maxwell to come and you know shake me um but so I was curious just at a very sort of high level you've you've gone from biology so thinking about biological feasibility to modeling and artificial intelligence and trying to ground something in you know trying to take biotic cognition and say well what makes that intelligent and then can we replicate that in silico or you know in a robot I was just wondering how biologically feasible are certain assumptions made by active inference modelers for example active modelers talk about um this again not exactly my but a mean field approximation for example where presumably you know the the hidden States or the different tenses have conditional Independence how you can take that one you can take any other just any other assumptions more broadly you know does this seem to you actually biologically feasible or is it just like an interesting modeling tool no yeah I it's actually those are those those are probably the most interesting and important examples of the assumptions we make so I think the biggest one in one word is factorization the the models both the generative model that animals have as well as their um Q their approximate posterior which they optimize using free energy minimization those almost necessarily have to be simplified in my opinion there's some people who believe that the brain is doing like sampling based inference in which case they can actually be doing full posteriors in which they don't need any simplifications in their model of the world they're doing full posterior inference on their model model I don't think that really holds up because it's it's way too slow to be um useful for for the time scale that biology needs to work on so I think those assumptions like factorization in the generative model those are quite realistic and factorization in the posterior in this approximate posterior I think that's actually one of the coolest things about variational inference is it seems like something that brains can do because once you make these factorization assumptions what it gives you are updates to your beliefs that are beautifully local like they they only need nearby information and this is kind of the the whole um uh rallying Cry of people like Bert Dev um who work on these message passing and Factor graph schemes what's beautiful about that is it's distributed in local and that locality inherits from the fact that we're making factorizations or we're making assumptions of certain variables in my model or in my beliefs are independent of each other the the the like a specific question is is the mean field factorization appropriate that one assumes that all the different state factors are conditionally independent actually just fully independent that one I think is a is an open question and so there's there's basically a knob we can turn from like fully factorized where everything's super cheap and local but you're introducing approximation error as soon as you start making these assumptions your beliefs are not going to be as good at actually explaining the data and minimizing free energy other side we have fully enumerated combinatoric entangled beliefs and explanations for the world which are maybe the most accurate but doing inference on them is going to be expensive and take a long time so the open question in my mind for biology if we were're trying to really map biological processes to like variational Bas and inference is like where on that sliding scale is biology or our particular systems so a lot of the work that we're trying to do at versus is basically find good settings of that knob like we want to figure out what is a a setting of factorization of complexity we can build into these models that they're still sufficiently expressive and um and generalizable they generalize across context across tasks but they're not computationally insane like we we need to make things cheap and we need to also we would ideally like to make them cheap enough that we could imagine neural wetwear implementing them with like local computation awesome yeah yeah that's yes I mean I guess that is the kind of well that's always the accuracy complexity tradeoff right I mean it's built into the very equations um yeah exactly I started in my introduction by asking about a well I mentioned in my introduction the parentology and actually this was probably the first question I ever had in when I discovered active inference what you know a year and a bit ago which is what what is free energy right like is there a little sensor in the brain that is like cued into this like again this was me being very naive is this like little thing and it's sensing free energy and it's trying to get it down to this minimum which again now I think about it obviously implies some kind of action policy that need you know is descending down fore energy gradients so but like it is a naive question but in some ways it's useful I think because it feeds into an intuition which is human you know there's this long stand there was a longstanding debate about like what life is right I mean like theal is there like some special source that we put into humans that just like means that we self-organize and I guess this is just a perennial problem which is well why are we doing this in the first place right kle tells us that if we are doing you know if we are if I can say that you're Conor today and your Conor tomorrow I can kind of describe what you've done but like why you do that is a kind of mystery and I think some people intuitively think well you know maybe there's adaptive sensor in the brain which tracks like this kind of special you know thing called free energy which is probably not happening let's be honest um and it's obviously an information theoretic term that makes things comput you tractable from a modeling perspective but when you're talking about putting that into an artificial agent the question that comes to my mind is is there anything else that you need to do is there a higher order prior for example you need to put into it that means that it actually will act to minimize variational free energy that actually will self organize because there it's kind of like why does a computer work like what I've always just like what's the kind of fundamental thing maybe in the case of computer or humans it's electricity is it anything like that you need to kind of put in that means that it just doesn't just sit there and it's built with these beautiful PRI but doesn't really act in accordance with them yeah yeah no that's a really deep question I mean so at a fundamental level you're I totally agree with you that there is no secret sauce there's no special signal as soon as I've written down any equation of motion that doesn't explode yeah any any equation of motion for systems that just generally keep existing another way of saying that is I've written down a free I can write the Dynamics of that system with some free energy functional so as designers of artificial systems we have the luxury of not having to write down an equation of motion that we know if we backed out the b mechanic of it oh look it's minimizing Frey we can start with the free energy so as as artificial Engineers we can say no we're gonna actually have these things integrate equations of motion that minimize free energy right so that's what we do but I but systems like self-organizing biological systems in the same way on on the Savannah the draft's necks are not getting longer to reach the trees because they want to optimize Fitness that's a post talk like apparently theological description for the Dynamics of systems and then we put a a sauce on it a descriptive sauce called Fitness or called natural selection that's the exact same thing with free energy there's just Dynamics and then post talk we dress it up with well these these Dynamics look like they're actually doing approximate basian inference and that's a cool useful in my opinion framing in the same way natural selection is a cool useful framing for statistical filtering of phenotypes over Generations but as artificers as Builders and Engineers we can actually we can actually write systems that optimize Fitness we can write an algorithm we could write a genetic algorithm that does it automatically kind of we can also write an algorithm that directly surfs a fitness landscape and in the same way we can directly write algorithms that minimize free energy the problem is like we now have the bir enough proof of having to write down a gener model and to to figure out what the free energy the best free energy functional for for a given um task is I think a more like almost like complex systems way of Designing a system would be to actually just like design a bunch of particles in a vat and write and like basically design physics like design a a particular sandbox of physics that emergently gives rise to agents that minimize free energy without actually plugging that in at the lower but that that's hard though yeah that's the that that's kind of where I was leaning right like I see yeah I guess like it just BR it bring it does bring into mind sort of just fundamental questions of tileology yeah uh and makes you think well why is physics doing this in the first place um and as you say like can we have like it probably would be in silico can we get these kind of particles that just do it and is there a way that we could get to the bottom of that rung without invoking another axium or another miracle or another process and maybe not you know it's um yeah that's yeah is you're thinking that if we did it that way so we started by just like writing down very simple physics of like particles in a vat and then we we get the maian mechanics emergent for free is because I thought about this as well in your thinking is that like is there an advantage to doing it that way rather than top down well I think I think that's in AG in the sense that to to my kind of eyes there's a slight difference in between natural selection and VAR and active inference and that's because I think um with natural selection you get both the principle and the process um now there are obviously some axioms and miracles now I'm not a I'm not a geneticist so don't shoot you know don't shoot the messenger but like the basic idea obviously is that you get the mutations and mutations are what Drive natural selection because it leads to kind differentiation within the pool of genes if you take a very sort Gene focused form of Darwin darwi natural selection but that gives you both the principle okay over time given mutations you there will be optimization for Fitness just for free because you just get obviously you get the things that are successful in you know the genes that permit repr reproducing themselves being reproduced and so on but with variational free energy and active inference and the free energy principle you get a principle what you don't necessarily get is the process namely what KL tells you is if things persist this is what they have to we can describe them using these mechanics it doesn't give you why things persist M so that's kind of what I mean and I do think that if you had a kind of completely neutral system because Okay the reason why some of these queries come to mind is because I think in the older papers the older active influence papers they would very subtly squeeze in this thing where it would say well there's also the higher order prior that or higher order action policy to minimize free energy and then that I think is a very philosophically FR thing because then you go well is there a higher order policy for that policy and so on right and evolution obviously grounds some of this out but it makes me think like sure it's a really lovely scientific tool but the power is really in the process theories whether that's coding active influence variational message passing PP scheme or whatever you want because you don't get the process for free from the free energy principle and I think in that there's a slight difference with Evolution totally yeah I I see exactly what you mean yeah I mean I guess one I so it depends on how you define evolution I would potentially argue that natural selection is even happening in nonbi olical systems and it's just the the process theory that provides the equivalent of mutation is maybe slightly different right but I guess you could still say that well there's still a mutation like it's it's it's just yeah it's a change exactly I think I I my hunch is that something like that could also be identified for a variational free energy minimization but I think it would be something that maybe would not be satisfying like Dynamics like you need which is another way of saying change you need some function that Maps a state to another state and that if you iteratively apply that function it doesn't diverge to Infinity yeah and I think that would be like the kind of process theoretic equivalent of mutation in in natural selection yeah I'm I'm sure someone's gonna do it it probably won't be me probably will be Cole let's be honest um yeah it comes back I think to this idea that Kate was talking about in I haven't read her book but I know it's out which is the maybe a slight concern with active inference and the free energy principle is that at its very core it rests on some kind of determined characteristics mhm and maybe I mean all theories have their axioms right I mean all theories have their miracles and natural selection definitely has its Miracles but it's very neat and clever and it all wraps up quite nicely and yeah I think you're absolutely right that maybe there's a little bit more work to do to really get the process of like why things don't just fall the part I mean this Ringer's big question right I mean yeah and Call's big question but yeah I think it's very important for an audience to realize that when we talk about Act of inference being the overarching theory of everything that's probably never never really made those claims yeah I I totally agree we we need we don't have the physics of why things don't fall apart yet we've assumed that that physics works and is there and then we do the free energy yeah yeah yeah yeah yeah and which makes one think and this is no disrespect to Carl or you or maxw or anyone who's deeply invested in this like exactly how much are we getting out of the free energy principle because I think Carl himself takes a very deflationary or torist count of the free energy principle which is that it just says if things persist they act and perceive like things that would persist do right like they act things act in accordance with themselves if they are to exist as themselves but as I said how things do that right you have to do that if if I make the fundamental free competition you are the same thing today as tomorrow like you have to at least be obeying by that principle how you do that well I guess we'll never well we might know um con this was really really fun um no it's these are wonderful deep questions and I'm actually just very glad I think something that people need to be more of is epistemically humble um and say where they don't know the answer and I'm very much in admiration of the fact that you're willing to say that there are plenty of things that this community still doesn't know um oh than yeah so and yeah the insights are just wonderful I mean I my final question actually is just a curious curiosity which is you were a neuroscientist right so Master's Neuroscience PhD Neuroscience how on Earth did you learn all the maths and the physics just curiosity no that's a a great question um yeah so I I did my bachelor's in kind of more cognitive Neuroscience doing a lot of EEG psycholinguistic stuff so not really math heavy at all and then in my last year of Bachelors I took one um computational Neuroscience class at University of Pennsylvania it was VJ balas Superman and he was the teacher um and it just really turned my mind not only to comp neuro but then all the methods that you need to know to do proper computation neur size and that kind of just opened the Pandora's Box a little bit and then I did a two-year internship at the National Institute on drug abuse and we were doing again like translational pre-clinical Neuroscience working with rats and mice and just during the evenings during that that two-year stint I was taking all these like machine learning and computational Neuroscience classes that at the time in like 2015 we're still like free on corsera so like Andrew in's course Jeff hinton's class and I yeah I just like had to teach myself a bunch of math um and it was annoying and hard but it I I think it it helps me catch up a lot to a point where I could then go and read Carl's papers and actually like kind of understand what's going on yeah but it was definitely a really long and like self-taught journey and because of that I do have a lot of like foundational gaps in math that people like Lance to Costo like you can clearly tell by talking to him he doesn't have those gaps because he has that that proper education well I'll tell you there's one man with the biggest gap of them all and that's me so um the PHD will be fun um it'll be great yeah yeah we'll be bootstrapping our way to some kind of mathematical adequacy definitely wonderful wonderful wonderful wonderful so much to think about um so many wonderful insights and great intuitions and yeah it's just been an absolute pleasure on my part and I'm sure everyone will benefit accordingly so thanks yeah it's been so nice thanks for inviting me in the first place and it was really a pleasure talking to you it was great wonderful Connor Thank you so so much again thank you 
