**Refined Text:**

Greetings to all and welcome back to "Active Inference Insights." I am your host, Darius Parvaneh, and today I have the distinct honor of speaking with one of the most significant philosophers of this century, Professor Thomas Metzinger. Professor Metzinger is an Emeritus Professor of Theoretical Philosophy at Johannes Gutenberg University of Mainz, co-founder of the German Effective Altruism Foundation, and president of the Barmherzige Brüder Foundation. In 2019, he founded the Minimal Phenomenal Experience (MPE) project, and earlier this year, he published "The Elephant and the Blind," which compiles over 500 experiential reports to provide the first comprehensive account of states of pure consciousness. His research primarily focuses on consciousness, and he is renowned for developing the Self-Model Theory of Subjectivity (SMT).

Professor Metzinger, we have communicated via email, but it is a pleasure to see you, even if only virtually. I sincerely appreciate your presence here today. Anyone who knows me is aware of my admiration for your work. In the latest version of the "Flow States" paper, your citations span multiple years, which speaks to your extensive contributions to the field.

In relation to your work, I feel that the past year has been a blend of active inference and Metzinger's theories. Let us commence by outlining the Self-Model Theory of Subjectivity (SMT), as it may initially seem counterintuitive to some. Could you provide a brief overview of the fundamental claims or axioms of the SMT, particularly concerning its key constraints, such as transparency and globality?

In the Anglo-Saxon discourse, there exists a rather inaccessible book from 2003 titled "Being No One," which has a precursor that many may not be aware of within the German academic system. We have two primary theses: a PhD thesis followed by a habilitation thesis, which is significantly more extensive. My habilitation committee consisted of 17 members, and in 1993, I published a book titled "Subject and Self Model," with the subtitle "The Perspectival Nature of Phenomenal States from the Perspective of a Naturalist Theory of Mental Representation." This already indicates the essence of the subject matter.

As a founding member of the consciousness community and the Association for the Scientific Study of Consciousness in 1994, I have always maintained that consciousness is not a singular problem but rather a collection of issues—some empirical and others conceptual. I posited that the most challenging aspect is understanding the first-person perspective and what constitutes a subjective state within any given information processing system. After a decade of research, I experienced a pivotal year at UC San Diego, where Paul and Patricia Churchland hosted me. During this time, I wrote the entire manuscript in English and revised it in the Humanities and Social Sciences building. I realized that American audiences required a more straightforward title, leading to "Being No One."

The underlying idea of this work, while indirectly contributing to the consciousness debate, is to examine the nature of the first-person perspective. In neuroscience and philosophy, there is often a presumption regarding the concept of first-person perspectives, treated as a fundamental concept, as if we all inherently understand it. However, this notion is a hybrid metaphor, combining the first-person pronoun with geometric perspectives. From this viewpoint, one could argue that it represents the epistemic perspective a system attains when it can refer to itself in the first person singular, as in the statement "I am particularly happy and relaxed right now," thereby attributing a phenomenal state to itself. This definition, however, excludes all systems that cannot utilize language, including higher vertebrates and other animals.

I believe that a first-person perspective is a model of the intentionality relationship. My intellectual evolution was marked by the discovery of Anglo-Saxon analytical philosophy of mind, which liberated me from the continental philosophical tradition in which I was raised. I owe a debt of gratitude to older philosophers who introduced analytical philosophy of mind to German philosophy, enabling us to recognize that philosophical discourse continued to thrive elsewhere despite the devastation experienced in our own country.

My work emphasizes the importance of taking conscious experience seriously, as it has often been overlooked by mainstream neuroscience. Additionally, I advocate for an interdisciplinary approach that integrates analytical philosophy of mind with neuroscience and cognitive science. An influential moment for me was the advent of connectionism and neural networks, particularly the works of Clark and Churchland in the late 1980s. In 2010, I decided against engaging with formal-level discussions of these theories, as I felt my age rendered me less inclined to pursue them.

In the 2003 book, when I referred to mental models, I did not mean it in a strictly terminological sense. My inspiration for the concept of self-model stems from Philip Johnson-Laird's work on mental models, which discusses relational data structures. This idea is rooted in a long-standing tradition of mental representation theories in German philosophy, which I explored in depth two decades ago. A crucial figure in this discourse is Kenneth Craik, whose 1943 book "The Nature of Explanation" introduced the concept of models as relational data structures that exhibit partial homomorphism with the structures they represent.

Step one in my formulation is to apply this to conscious self-representation, proposing the existence of a phenomenal self-model beyond linguistic representation. Step two involves the notion of transparency, which originated in the UK with G.E. Moore, applied to the phenomenal self-model. This inquiry examines what occurs when a system's model of itself—integrated and global—is transparent, meaning it cannot be experienced as an internal representation. Finally, step three investigates what additional factors are necessary for generating a consciously experienced first-person perspective.

You may imagine a scenario where some human beings are entirely conscious and aware, possessing a self-model, yet lacking a subjective perspective on the world. I theorize that systems like ours even model the intentionality relationship. The research question remains: what constitutes the self-model, and how does it relate to consciousness? The main point is that many interpret this as a theory of consciousness, whereas my aim is to elucidate the experience of subjectivity.

I have observed a chronological development in your work, particularly toward the epistemic agent model around 2013-2014. However, I would like to explore the earlier work, especially your 2005 paper "Prey to Being No One," which discusses simulation and emulation. This paper introduces the idea of a self-model as an emulating and simulating system, with the target system being identical to the self-model. This concept raises intriguing questions about the nature of phenomenality and subjective experience.

You have posited that the emulating and simulating system is inherently identical to the target system. Is this to suggest that they are entirely identical in terms of neurocognitive mechanisms, or does a higher-order network exist in organisms with self-models, dedicated solely to the act of simulation and emulation?

This question is quite complex. I believe that the phenomenal self-model currently active in your brain is strictly identical to a specific subset of your brain's properties. It may be best described on a functionalist level as a computational time slice within a process. It is not identical to your entire being, as the subject is the organism as a whole. The organism has developed a neurocomputational tool—namely, the phenomenal self-model—to attain knowledge about itself.

When we assert that the phenomenal self-model and the epistemic subject are identical, it is not entirely accurate. The epistemic subject possesses conscious self-knowledge, while the intentional object refers to what it is directed at—the organism as a whole. The tool utilized for this representation resides solely in the nervous system. Thus, while they are not identical, the distinction lies in the relationship between the epistemic subject and the intentional object.

Addressing your concern, neuroscientists often argue that the nervous system comprises electrical signals, with no inherent distinction between self and world. This raises the question of whether a computational mechanism is necessary for differentiation. As you noted, the self-model is always embedded in a world model, necessitating a mechanism that allows the system to emulate and simulate itself without conflating itself with the entire world.

It is important to distinguish between the representational level of the self-model, which encompasses the entire organism, and a functional level of description based on its causal structure. Any given moment features a neurobiological implementation, and the distinction between a computational self-model and a phenomenal self-model is crucial. The intuitive notion of the ego and the experience of oneself as a thinking and feeling entity typically characterize the phenomenal self-model during waking states.

In contrast, the computational self-model encompasses the internal states that are predictions about future events and experiences. Although technically an internal process, the self-model robustly presents itself as external reality. This leads to the question of how living systems maintain this distinction between self and world.

Many nested Markov blankets exist, forming statistical boundaries within a living system. When a system alters its environment to conform to an internal target state, the human self-model may dynamically engage with its surroundings. I maintain that conscious experience is fundamentally determined by local neural activity in the brain, even if complex causal loops occur within the environment.

I often contemplate the origin of self-models, and I propose that the immune system is a likely candidate. This low-level process effectively maintains boundaries between self and non-self, constituting one of the earliest forms of self-modeling. While this model may not be localized within the nervous system, it is vital to understand the evolution of self-representation.

As I reflect on my career spanning from 1993 to 2024, I recognize significant changes in my perspectives. I have adapted my views on the Self-Model Theory and its implications for consciousness and selfhood. I appreciate the opportunity to discuss these topics with you, Darius, and I look forward to further exploring our shared interests.

**List of Changes Made:**
1. Corrected grammatical errors and improved sentence structure for clarity.
2. Replaced informal language with formal academic language.
3. Removed unnecessary repetitions and trivial statements.
4. Organized the text into coherent paragraphs for better flow and readability.
5. Clarified the main ideas and arguments to enhance understanding.
6. Maintained the original meaning while ensuring precision in terminology.
