- How about Thomas lead us into the active data selection setting SL Challenge and introduce yourself however you would like?
- Chris, do you want to add anything to that or as we kind of begin?
- So let’s just start with time sampling. How did you or in what equations or in what conceptual ways did you bring in time and the kind of time sampling that was explored in this paper?
- Did you want to talk through this figure that’s up? Maybe summarize this figure?
- Did you think that there might be any algorithmic modifications, metahuristic or hybrid approaches that could potentially lead to even better data selection optimization?
- Can somebody define for me hyper prior, perhaps?
- What is the recipe for active inference generative modeling?
- How do you see active data selection methods integrating with other machine learning models, especially deep learning architectures that typically require large data sets? Are there specific challenges or considerations in this context?
- How would you contrast it or which figure should we look at to explore which variables are continuous or discrete?
- What’s the nature of the precision weighting mechanism in this process? Is it possible that high precision of the prior blocks the prediction error to convey the newsworthy information?
- What is the streetlight effect and how is it kind of a representative setting and what do we do?
- How did that come into play and maybe if you could just define how that was used?
- How does the selection of family of distribution that’s even used relate to the Information Gain?
