all right welcome back cohort 5 we are in our second discussion on chapter nine so Andrew or anyone else who wants to write a question or raise their hand let's just jump into it okay I just heard the recording in progress thing maybe there's something about Pete's Coffee that causes a time dilation but either way now we're in chapter nine so where shall We Begin yeah I was going to say if anyone has any particular points they want to get into with this chapter happy to jump into those otherwise um if anyone's like you know only able to make this meeting ween able to make the last one I'm happy to kind of give a general overview of what's going on here uh if you don't mind a general overview would be good to start with if other s c yeah go for it previous meeting is at 11:00 in the at night in my time so I I haven't been uh able to make them so General overview would be really helpful for me if if it's a possibility yeah great um yeah let's do that and there is a lot going on in this you know this chapter this is sort of the aside from chapter 6 which gives us a general recipe for composing uh gener generative models and kind of the more General method you might take here in actually applying active inference in the second half of the book um recall in chapter 7even we're given the um PDP model how to construct that chapter eight we're given more continuous models and then here we bring it back to okay so how do we actually use these models and construct them in a way that we can apply them to empirical experiments where we're actually collecting real data um and so we're we're moving beyond the range of just purely building models and running simulations to collecting empirical data such as like neurophysiological data could be EEG it could be just observing um behavior of anywhere from human beings to to rats or if you're in more of a an engineering setting you might be looking at other kinds of data that's being extracted and you just basically we want to figure out how is that what are the what's the process uh that is generating that data which of course we may never know um but we can attempt to model it so um yeah this chapter it's it's quite dense I'll be honest whenever we incorporate everything um but it does give us a nice full flow of how to apply these methods to empirical data um so first of all in the introduction there's hints at what we'll find in the rest of the chapter um we're introduced to metab basian analysis which is where we actually view this as the agents subjective model versus our own objective model that we're building of the agent subjective model that kind of uh carries into the active inference ontology right just we do have to account for the fact that we are sort of the quote unquote objective scientists in this situation we're attempting to model the behavior um and other parameters of like an a separate being from ourselves like in a teamas we're trying to you know understand the subjective model of a rat which we don't have you know collecting data and applying analysis to see if we can do something like approximate it so here our goal is to what we would say is recover or infer the unknown parameters of they phrase it as the subject's brain its subjective model using our own objective just by drawing on the behavior in our observed data and then we uh invert our objective model to infer those parameters of the subjective model and then finally by doing so we can test and compare hypotheses for example we might find multiple models that we could build we could compare them and um and see which one holds best to like the behavioral outcomes that we're seeing in the data and then they they have another concept called computational phenotyping um this is where we kind of by by recovering model parameters prior beliefs of our agent we could actually like kind of classify um our our the individuals we're studying whether it be multiple rats and a teamas it could be clinical patients and more of a you know um uh in the study of Psychiatry but we can kind of phenotype those individuals based on what model we end up uh developing to try and explain their behavior um and so yeah this chapter lends itself really well to specifically computational Psychiatry and neuros pychology neurology but uh in principle all these methods could be applied to a broader much broader variety of phenomena whether it be or or even non-living systems um so section 9.2 um and again there's a lot going on in this chapter so I'm going to try to be a little bit more brief but are introduced to um just as we've seen basis theorem in previous chapters uh now we have equation 9.1 which looks almost exactly equivalent other than we've replaced uh observations and states with uh behavioral outcomes youu your actions to be taken and then a Theta symbol uh which represents the parameters of the model and so just as we can uh update a model's beliefs related to States observations the relationship between them in the form of likelihoods and posteriors you can do we're ideally doing that same exact thing here but now we're mapping outcomes to mod parameters and I'm going to pause here real quick bres you had a question uh yes uh actually uh I'm um I'm just wondering so you mentioned mention this computational yeah exactly this one you mentioned computational phenomenology and this subjective model are you saying that uh I don't know anything about it so I'm just asking uh are you saying that somebody can actually start uh plugging in values inside that uh uh that Matrix that you said like and there will be like like what I'm saying is the values which you encode into that and some and some variables since you encode will be part of that computational phenomen ology or How does it go yeah sure um so one thing we could do to try and answer that question is to look at like we have in section 9.5 just a nice like brief series of steps for how to go about this um and so like in Step One quite simple we collect behavioral data um you could even think of this as like a a spreadsheet or something along those lines like that kind of structure where each row can represent an individual like in a tm's example we have um rat number one rat number two we could have uh in the columns things like what are the what are the actions or that they took that we we saw whenever we collected the data um what are the associated observations um or or or other components of a model that we saw we could also have like other kinds of information like maybe the test was being done by administering um a drug to certain rats and not to others to try and study the impact right so we could have like a binary one or zero um like if for each rat if it was administered the drug or not um step two we formulate um a PDP this this chapter is a little bit on looking at discret models so a PDP as we were introduced to in chapter 7 although later they do give us a couple examples of um more continuous models and what we're trying to do with step two is that we're trying to develop basically yeah derive a model that like closely approximates what we see in the data that we just collected in Step One um but nonetheless we know that like this is our model so this is kind of that outer objective model that we're seeing in uh in the figure that Daniels pulled up there figure 9.1 so it's kind of that that inner box is the subjective model we're trying to to basically yeah devise our own objective model of what's going on in the rat's uh mind so to speak if we follow te's example um so that it there could be aspects of this that um because your question had to do with specifying priors um step three is specifying a likelihood function um and that's based on the model that we just tried to make then after that step four we specify prior beliefs um and so in that step the way they've written it we can specify prior beliefs about the parameters in terms of expectations and precisions often these will be centered on zero with precisions reflecting plausible ranges so you might think of that is you have your own hypothesis about what the prior beliefs are um and you just kind of roll with it so to speak you we're doing a process where we're trying to build a model that whenever we run that model it and and run a simulation with it hopefully it more or less approximates the real actions uh that say a rat and a teamas uh took as well as like the combination between those and the observations that the rap received so um hopefully that provided some kind of information or a bit of an answer to your question um but yeah I'm just trying to get to yeah sorry it was a great answer all add a little more so Pros you mentioned phenomenology like the kind of felt experience and this kind of made me think about like um three different kinds of phenotypes that you you might be studying you might be studying the most grossly morphological like just the actual bodily movement like the movement of an arm then there's kind of cognitive phenotypes that are internal they're not directly observed but they're also not like philosophical or metaphysical or phenomenological like um the motivational drive so mainly I'll I think I'll just type I I'll just type today since it's a little strange with the internet but suffice to say that the the phenomenological phenotypes like the felt experience is probably the most difficult because now you're not just talking about the where the arm is in location you're not just talking about the intent to move the arm or something like that but you're talking about like the experience and that is the the challenge that many researchers are focused on and hey Daniel I want to give you a heads up that uh the your audio is a little choppy as well but I do fine I'm just gonna type I'll just type yeah cool super helpful thanks great and then yeah I'll just follow through with um with those steps like after you specify those prior beliefs in step four step five we solve for posterior probability and model evidence so effectively what doing is we're just kind of continuing the process of like how do we approximate our subjects uh underst studies subjective model so like here are all the different components right all the ones that we've been familiar with is we've proceeded through the textbooks we have we're figuring out likelihood functions we're figuring out uh prior beliefs even if we're just setting them initially as like some value and and then need to kind of further carve out our model from there and maybe uh update those priors to to better reflect what's going on in the subjective model so um I think the word they repeatedly use this word recover like we're trying to recover the prior beliefs or recover the parameters of the model so there's no assumption that we know what these are from the onset instead we're we're attempting to build a model and then kind of fine-tune things from there to where they better approximate what might be the actual um priors and and the kind of likelihood and and uh model evidence and so on that the the agent is working with um I'll just put one comment so so you're saying that if um suppose we found some empirical study and we get get the exact value not exact value but like a like a distribution a Goan distribution of the prior then that will be that will be the best that will be very helpful right yeah presumably uh yeah if you find that so basically we are trying to iterate our model so that we can get to those kind of values which have a very accurate description of what the prior values exactly might be yeah something on those lines right so some some reverse engineering yeah you're right that's very right like we can just think of it as like we've been introduced to these sort of insilico synthetic models like in for example PDP we're already familiar at this point thanks to chapter 7even and other chapters like we'll hear all of the components of a PDP we have we have our D Vector which is our priors over you know initial States um we have our a matrix of likelihoods we have our B Matrix of State Transitions and so on but now when we've collected empirical data well we only have what we as the you know so-called objective science scientists can observe so we can observe uh you know an agents like a rats or human beings actions that they've taken and we can observe like maybe what was going on in the generative process like okay the mat the the rat was in a maze where the reward was on the left right so so we have our gnomes but they're not uh and given and and what we observe but they don't all match all of these different components of the PD P so we're attempting to kind of recover what's missing right we're we ourselves are under undergoing the active inference process of trying to to infer and learn uh what are the other components that we cannot directly observe of the rat's Behavior because then that way of course it starts to match you know anything else some other machine learning routine or something like we're just trying to find these unknown parameters in what we presume to be the rat's model subjective model yeah thank you sure absolutely and then um aside from being uh either introduced or given some kind of more technical refresher on what what methods we might use along the way to do this like they dedicate an entire section to variational Applause which kind of gives more description on how we're using this modified phase theorem now instead of with States and observations we have actions and we have um like model parameters um aside from yeah how it it reintroduces uh how we might yeah recover parameters via the llas approximation we also get a much more description ility of applying these methods in the first place which is in Step six of the the overall process uh that's introduced here and so it gets more into you know there's a lot of overlap between this and other more traditional uh analytic settings where you might be trying to do something like a covariant analysis or or a correlation analysis you might be trying to as I mentioned earlier with a Tas example where maybe a drug was administered to certain rats and not to others let's do some kind of group level analysis to see what are the patterns in the Behavior Uh and outcomes for the rats who were administered the drug versus those who are not right so this this is getting into much more again like kind of traditional settings where really you're just applying analysis um but now you have the the added utility that you've Dei you've devised an entire like in this case PDP that can potentially like really strongly explain a rat behavior and you have all these different components and parameters that you've recovered to allow for quite broad variety of analyses Beyond just beyond just running like a simple like T Test or or um yeah looking at correlation between certain behaviors and and outcomes and that's all we have so yeah that's that's the general process I think that that figure 9.2 does a rather good job of trying to visualize the the six-step process collect data we build our own objetive our initial objective model of what how we think that that data is produced we derive like a likelihood function step four prior beliefs we set those step five we invert the model which we're already familiar with doing uh previously in the book like that's how you go from a model an agent who has priors and likelihoods and then those can be mapped through bases theorem to a posterior and model evidence and so everything actually looks kind of structurally equivalent right um to that equation and finally we move on to the final analysis yeah P um actually I have a question so so what about if we if you are um like we don't exactly follow the likelihood function the way they given where they're giving uh but we uh introduce our own function which actually does the likelihood mapping like not a function or or a methodology and uh on top of it so so so actually the fundamentally like we're using this Marian processes to do the state transitions right so we have flexibility that we use uh uh we what I'm actually trying to say is that this three this likelihood function right which starts from the policy level uh right fundamentally down to the observation level and uh instead of following the exact mechanism which they give we can introduce our own methods but we uh do the mapping of transitions across States and the observation mapping like the a matrix and the B Matrix we keep it very similar uh but the other uh the the the higher levels the higher uh levels that can plausibly be changed also right if we it's like we can apply a free energy principle to that also I'm just uh I'm just think on those lines I've not been able to formalize it very cleanly but uh I hope that in a few weeks time I'll have more clarity um so that's just what I was trying to understand you know fundamentally we do this um uh surprise minimization the the most quote principle and then the transition mapping but the later above layers like say policies and affordances we can actually create a methodology which fundamentally does that but not exactly through this very uh complex basan mechanisms uh that's just what I'm trying to say it's like there there can be other methods like to accomplish those policies and affordances MH I'll I'll see if I can if it will work it's a very interesting question and and it makes me think that this is like a policy selection but you're not actually choosing the policy but it's trying to develop a function that does map from all of the model and parameters to the choice of policy so it's kind of like policy selection from the outside and then we have the view from the inside view from the outside and maybe there are some other heris STS or rules that could be simplifying in terms of how we do the policy inference uh sorry actually I couldn't hear but you think policy inference will be will be from inside right or you're saying it'll be from outside I don't understand well Pi is usually how we think about policy selection from the inside but we're the behavioral experimentor we're only observing the the U the emitted behaviors so we're developing a model in step three that that is is the distribution of the emitted Behavior given all of the parameters many of which the subject doesn't have access to Daniel just a quick heads up your your audios it's still kind of choppy there um but I think you were making the the point that yeah like whenever we've collected the data we have access ourselves to what were the the behavioral outcomes I.E whenever we were looking at equation like the Tilda U that is a series of actions um the Tilda always Den know it's like a sequence and then you being an individual action and so with a policy you can think of a policy as a series of actions like the um know we have like a rat and a teamas action one it takes a hint as to where the reward is action two it goes to where the reward is as As Told by the hint um so so now we have like a number of actions in a sequence like a Time step one it did this time step two it did this um and that can be represented as the U Tilda which could also be represented as an individual policy so um a rat who really already thinks that the reward is on the left it'll skip the hint it'll go right to that reward right so we see a c we can associate a certain sequence of actions uh with uh you know this this actual behavior that we see it's it's equivalent and then whenever we're looking that equation it's like okay well why did the rat jump right to the reward like what parameters are in the model that would push it into that kind of behavior rather than the kind of you know safer policy of going for the hint first um and so that's what we're trying to kind of recover like what are those parameters that are determining that uh given that we only know the actions that it took we don't know all of these underlying parameters and and you know cognitive parameters or otherwise we don't necessarily know um priors we don't necessarily know how much the rat like another thing that we get introduced to in this book is whenever an agent has extremely strong priors like a rat who just really really wants the cheese uh and and doesn't even really care it's it's uh not very uh risk ofers so it doesn't really care if it ends up you know choosing the wrong option and getting a small shock or something it'll run right to the cheese um those are all yeah parameter settings that are determining that and those are the parameters settings that we're trying to recover uh in the model inversion process and that's why at step five we get this like reverse uh view of that same equation instead of we have instead of having a sequence of actions given a parameter now we're trying to find what is that parameter given the actual actions that we that we observed that kind of tracks um I'm sorry Andrew uh basic question could you please tell those values what what is a p mu Tilda that's the policy what is Theta what is what is O and what is M yes for sure um Theta are your model parameters it's kind of it's sort of like a collection of all these different parameters that might be involved in the model right so um a lot of notation in other areas in active inference and elsewhere it's like normally they would kind of put that in bold just to to denote like oh this is a collection of different things it's not just like a single value right so that might have been helpful if they used that um but but yeah so the Theta are just these parameters that we're trying to recover about the model m is just a symbol um that throughout the book sometimes you see an M uh being included in an equation sometimes you don't uh but more often than not uh it's implicit that m is almost always there m just denotes this is a model like there's a model in here and so it has its own parameters it exists uh just point blank like there's a model involved here and so we have to say like technically all of these parameters are conditioned on the fact that we have them specified maybe in a certain way for example the M might also along the idea that oh yeah this is specifically a model um in the form of a PDP versus a different kind of model um so it's it's kind of there in part just as a reminder and that's why it's often left out because it's already implicit that it's always there um and then finally the uh Tilda o that is our sequence of observations and so with a rat like in a tze just as we had oh the rat like action one the the till a youu it first it took the hint then after that it went for the reward we know that those are are recorded actions that the rat took we also know the observations that is oh the rat whenever it took the action of going to the hint we know that it observed the hint um so we can track that action number two two it went for the reward and it it successfully got it it got the cheese the observation in that case at time step two is that the the rat observed the reward so just as we have a sequence of actions we also have an Associated sequence of observations and those are kind of our two those are the two things that we collect in empirical data by which we now have like hopefully enough components to try and do this model inversion and extract those parameters that we cannot directly observe is that helpful uh sure can I can I just uh clarify what I understood yes absolutely okay sure so so what is saying is so okay m is the model which we can think is think of like a configuration setting initially which we pass on to the entire system right uh like because every model can have a different configuration setting maybe that that might serve what I'm saying um your o o Tilda right what is it o o bar oar is like your it's a Dela of observation squ bar yeah and then this O Bar is like it can be more than one observation right it can be like a sequence of observations but don't exctly State how what is the length of the what is the what is like the slot of the sequence right so we do technically know that like in a um like a team's example like based on your yeah we have a certain number of time steps so it's like because that's that's what the PDP is about it's about discrete time steps so it's like time step one the rat starts in the center like it's done nothing there are no new observations necessarily or maybe we say it didn't observe anything it's just time step one there it is time step two um it then goes to get the H it observes the hint so now at time step two we're able to record here's the action it took and here is the observation it had it observe the hint then time step three it decides to move to the left arm of the maze uh and so we know that its action it took the U is that it moved left and then it observed a reward and so time step 3's uh o is it observed a reward so you can imagine that is like two vectors almost of like here's time step one here's time step two here's time step three here's the vector of actions it took from time step one two three here are the the observations it had at time steps one two three the threes are typical over here yeah in this case it's it's been done in different ways uh for the teammate's example for example and and it's it's really useful because you can do things like try and study the the so-called explore exploit tradeoff so imagine you you allow for four time steps um it's where the rat starts and then it can choose to take the hint or knot and then it can go to the reward well if you have four time steps if the rat skips the hint and goes straight to the reward well now that you have that additional time step the rat can spend more time with the reward and so it's like you if you think about it in terms of it like maximizing its utility or reward it's like oh it gets to spend a whole extra time step with that cheese like that's you know great it skipped the explore Behavior went straight to the exploit Behavior to get as much cheese as it could um but then you can use that to try and study like oh this is a very like risk-taking rat right so it chose to do that uh versus other rats who might be more uh conservative and like go for the the risk uh excuse me go for the hint first even though they're giving up that additional time step that they could spend getting like spending more time with the reward and then finally you could also have very risk averse rats who like you know maybe they got shocked a couple times and they have preferences to really not get shocked uh that that those negative consequences in terms of its preference yeah highly outweigh its preference for the reward in which case you might have have a rat who just stays in the center the entire time or it might go to the hint as a exploratory Behavior to gather more info it might go to the hint and not even trust it depending on how you set up the situation and it might stay at the hint and never go for the reward it just really wants to know it's you know so is it's as if it's so about this stive way because it's a real animal but like maybe it's so scared that it just keeps attempting to gather more info um and never goes for the exploit Behavior so hopefully that's maybe a kind of an illustration of like you know we we we we can choose the number of time steps whenever it comes to discrete time models like this and so we can easily just index like time step one time step two Etc was that was that helpful at all per Kush I might have been over descriptive with the t- example there plenty of examples actually my internet got blocked out also I had to reconnect but but actually I think I get get the picture I I like this uh this that model example yeah yeah I think it's a a worthwhile one just because this chapter spends time on it and that's kind of that figure 9.2 it's like here's the series of steps you would take if you were doing the te's example so it's like for anything that still seems ambiguous or uncertain hopefully I'm giving enough info that you would come back to the chapter and see like okay like I get it now with the team's example uh Francis you had a question yeah um so that's uh really interesting and really helpful thank you um am I this maybe a kind of blindingly obvious uh question is the focus of this book or indeed of the active inference program in the general sense more about understanding active inference as it exists uh rather than say developing active inference as a generic AI technology to solve uh um issues where we're not necessarily the model the generative model is not necessarily active inference related yeah I think that's a really interesting question um and it might [Music] be somewhere between an answer to that might be somewhere between uh more objective versus versus highly opin nated um but I'll so I'll give my answer uh which is as far as I'm aware and looking at where um you know active inference can be applied to just kind of a ton of an immense amount of phenomena um like here we're given chapter n applying active inference to imper where it be applied to empirical data that we're collecting and so we're looking at like actual agents um active inference has many of its foundations and you know the work of Carl friston and others who are coming from a neurological neurobiological background and so there there is there has been kind of a big push initially to use this for for those fields and so computational Psychiatry and so on and we get a variet of examples uh of how that's been done in this in this textbook itself in this chapter like table 9.1 they provide a you know an entire annotated like big bibliography of all these different works on uh delusions and um pharmacotherapy interventions and so on but that said um know you could you could build models that like are entirely in silico that don't have to do with anal I in you know animals or human beings um like on Thursday mornings we were using um RX and fur which is a package developed in Julia to to try and build in silico experiments and so what I'm saying with that is you could use these tools to build AI or or otherwise different kinds of Behavioral Systems um that you could you know try and employ in the physical world like you could build a you know a robot that has its own sensory modalities it can see you know visually what's going on and then try and infer what kind of actions it should take and realiz it preference and of course like if we build a robot unless you're trying to actually emulate a human being or a rat but probably not you're probably building it to add to our reality and can some kind of new function in society or otherwise right in that case now it would be more about like we're starting with make you know simulating something on a computer that maybe one day can be realized in the form of like a physical machine um so yeah it's kind of like these two worlds right it's like we can build active inference models to try and better understand the world around us or we can build models that we can then actually employ you know in the form of AI in in society for whatever your use case is um yeah and and so you'll see a lot more literature that's been published including since the textbook that lends itself more to the latter approach that I described but again of course this textbook is co-written with friston and other folks and with a neurobiological background so I I think if if you really want to rely just on this textbook you probably will get much more of the flavor the kind of yeah psychological psychiatric biological flavoring of active inference I hope that that was a helpful uh kind of opinion that I shared there y thanks I think that was very helped to clarify uh what I was feeling my way towards thanks sure absolutely um yeah bries question yeah hi uh Andrew I was uh I was since you mentioned about uh this this Julia thing right and uh I was planning to join but I've not been joining because I think I will start joining uh maybe the week after next after I complet few things but I have a question uh so I have never used Julia before but I I'm seeing that it's quite powerful and it's very fast right that's the most uh uh it's like it's um why people are using it but I'm also wondering since uh does it have Integrations with suppos say to tools like neo4j and has anybody worked on that like I was just seeing that they have a driver called bold. JL which does this I know I don't want to explore so much it' be crazy but what I was thinking is if if we have like um uh okay let me let me make the question a little bit more simpler uh have you guys worked on any kind of int is it entirely within the jul or do also do some kind of Integrations suppose um sure because like in Python the if if I use Python for example like and I used want to use other platforms also uh the Integrations are like much more um like there are like good libraries which will help us but over here it will require a little bit more level of like we we've not jumped into this knowing uh for for example Julia and inside and out actually a PhD student who's working directly with the people who uh developed our xenfer so we do have like a little bit of support from someone who's been directly involved in in building out the the package and and resources um but the majority of us have not even coded in Julia before so so it's primarily like mini of us just kind of learning this together and we're going through um another nice thing RX Ander has a their website um where they've provided a series of like different coding examples for like different use cases uh we did one that that that follows um AR Roomba like a small you know machine that cleans your home and trying to model like an inference process so that it can it can derive like a likelihood of like oh if I'm on top of tiles I must be in the bathroom if I'm uh you know seeing a hardwood floor I must be in the living room and so so we just get these like nice like uh sort of real world use cases um where we get to follow along and figure out how the code is functioning there and more specifically getting back to your question though and integration um I'm still learning that myself so I can't give a terribly holistic answer but what I can say say is that anytime we've uh run through any of these examples for the most part we're really just using like uh an updated Baseline you know Julia like install that on your machine pull it up uh we use a nice uh visual editor called VSS code uh if you may or may not already be familiar with that and then um in terms of just like bringing in the packages we're using for the most part it's just RX and fur it's not a ton of well okay to be fair that has its own dependencies as well um but yeah RX INF fur aims to be kind of holistic like this is the one package you have to pull in and then maybe you pull in like an additional like nice um like plotting package so you can like visualize the results of the inference process or otherwise um that come out of ARX Ander but yeah I think it I think ARX infer aims to be a rather Standalone as asterisk um U package for for yeah building active inference models both uh both discreete time like pdps or even just not even going that far and mdp depends on your use case as well as uh continuous models and yeah it's quite strong and um as far as previous approaches to active inference like software wise we have mat lab uh which has been more geared toward around uh building discreete time models and uh python where the strongest like pre-established package for that that being a pi pmdp developed by uh Connor Hines and others that's almost entirely like exclusive to discrete time steps um so Julia yeah something about the combination of computational efficiency with like oh developers who are creating these new kind of holistic packages for just trying to develop everything in one go in a single script um that's that's able to handle continuous processes uh much better and and and kind of more holistically as well so um I don't know that was a lot but I hope that was just a followup question on Julia like what you're doing are you like trying to say create some functions which will say do a thing like say minimize surprise or say calculate varal free energy for you guys like just create a function which will do that are we thinking on those lines also yeah presumably you could Define your own um I mean it what's really interesting to me about Julia versus like python is that that that you can actually like type in a Theta and other symbols into the code itself as to write it out and so what I what I mean by bringing that up is that like you could certainly um write your own sort of objective functions uh to to energy minimization um what's nice is that arcs infer like some of its coding examples very specifically relate to active inference like it is explicit like an model building uh so there are functions like like they have this uh infer parenthesis function where you like here's your you plug in here's your model that you've just built here's your data simulate the behavior and then um they have a single argument for free energy true or false if you set it to true it will minimize free energy so it's kind of like all inhouse like uh out of the box like if you want to do free Min energy minimization there's um on their website they also have documentation for like is how they uh like within that that that function is the free that's being minimized because at this point we have a few different kinds of free energy uh and and formulations like in this textbook for example we're already introduced to the difference between variational free energy and expected energy and since then um there there's been more uh Research into other forms of free energy that highly relatable uh but nonetheless like for example trying to combine like how do we put together variational free energy and expected free energy into maybe an an even more concise single formulation with things like generalized energy another one be able to pronounce correctly but I think it's birth of energy or death energy free energy and that's that used in this RX infer package um so yeah suing it back up um there are ready to go like out of the box free energy objective functions in the package but you could um Define them yourself as well if you so chose and um Daniel's making a point with the notes one of the another benefit of the oener approach because I would say it's not just a package but there's there's a lot of documentation on how it's it's its own approach it is um highly relatable to the textbook we're going through and nonetheless it it kind of makes it attempts to make some kind of advances on on how to do active inference so we end up with these things called constrained forny Factor graphs um we already see all these different Factor graphs in in the textbook we're going through here um you know the the way the PDP looks with like its nodes edges and here's to visualize how it works ARX and F is doing the same thing but it's attempting to make each each node kind of self-contained almost such that uh you just account for its connections with other nodes and it will locally minimize its own free energy um in that case like rather than looking at a totality of the system minimizing some broader free energy uh now you can look at it as oh each node in this graph is is minimizing its own free energy based on its local connections only what's it called this allows what is it called what you saying all name please what you said what is it what is it called what's the name yes the constrained for Factor graph oh okay yeah and Daniel's type the cffg yeah yeah uh for sure and then you'll you'll see like in what's nice another thing is that in each of the um examples like so if you go to the RX infer website which um you know we've we've put links to that uh elsewhere in the Kota but uh a simple Google search of RX infer will will'll take you right there as well um each of the examples will site uh related paper so like here here's our code example we've kept it really concise for you but if you need more information on the simulation we're doing the components what the cffg looks like for this um you can just go to the reference paper that relates to it so I we're part of the pull here for doing this project is that we're also giving feedback on the documentation for the package since we we have this kind of direct connection with the developers themselves um but so we've really been kind of scrutinizing the the documentation a bit check check out cffg because the the whole idea is that you to you could you could go far beyond the kind of uh pdps we're seeing here uh in the textbook you weend with a kind of a standard recipe for building those but um a cffg because each of the no nodes is uh minimizing free energy locally you could end up building in principle whatever kind of want you could make it highly Lex all you have to do is specify here the nodes connects and uh you know it uses message passing algorithms underneath to to transfer all the messages between them but uh yeah you could make like any kind of arbitrary model um basically and and like derive like free energy minimization for each of those nodes and then you could potentially sum those up and look at like how the overall system is doing and such things like that but uh yeah the interest of time yeah I would just recommend looking more into the ARX and for a package and it sounds like something that might might interest you and then also we are posting in theota like uh our our notes and and what's coming up in the next meeting the other option the active inference as a direct these startups using active inference as a direct um AI uh approach uh rather than just using active INF rather than using active inference to Simply understand systems which understand yeah yeah no absolutely I think the the two kind of approaches go together to right because so much of this based upon Neuroscience research towards you can almost think of it as a one of them is eating the other if we can learn how biological organisms learn for example that that gives ideas of how to formulate a model that itself can learn and then moving from that to building like a pure AI That's just using many of those principles we've derived um for yeah generating its own behavior despite the fact that it itself is not a a rat or a human being or some such thing but yeah please absolutely feel free to to add to the code as you like questions or notes or thoughts think for them so I think we we've about sure all stop recording 
