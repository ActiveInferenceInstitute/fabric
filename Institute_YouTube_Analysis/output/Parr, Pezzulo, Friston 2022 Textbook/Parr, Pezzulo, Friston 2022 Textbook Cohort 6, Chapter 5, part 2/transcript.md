all right well thank you for that very interesting prior discussion on on latter texbook group so I hope that we can continue from that first few minutes that we had okay this is the last recorded discussion feel free to come next week for um the other cohorts also unrecorded discussion again we'll kind of like look over what has been written think about what we want to do with textbook group and everything kind of continuing so but here's chapter 5 and or like anything on the first half of the book like anyone could go any part from five or first half or we could look at the questions and look at which ones or spend a minute and upvote questions that we're interested in and then look at which ones have been upvoted a lot but not answered for first time sure question sound good okay in chapter five anyone can just people can be clicking the thumb and then we'll just go in these or raise your hand and like go for anything else but anything in chapter five that anybody wants to go to first um table 5.1 with the neurotransmitters um I think it's page 98 yep that's the one um so is what being stated here pretty much saying that you dopamine is increasing the Precision of you know the the brains uh you know I guess what the bra understands of of policies so it's saying you these policies are more precise if you know the uh a newon or a group of new on is getting more to mean yeah so to kind of like pull back on the table this is going to be linking specific molecules and roles they play in mechanisms in the brain to specific variables in generative models and then the table is like describing well here's some sheer anatomical facts these are empirical measurements and then also describing and citing some studies that might have studied um the relationship between like the activity level or the amount or the signal of some neurotransmitter to some aspect of a generative model and then that could be more correlative evidence like size of a brain region or um changes in the functional fmri um okay or it can be more causitive with like CH giving a manipulation and then showing that the two things are changing together so it doesn't mean it's the only function it does or its whole role or anything but it's just saying these parameters are being being identified are not just like weird statistical artifacts they map on to like natural components of behavior so it's proposing there some connection between your know dopamine and the policies that the brain is building there's to to really look at this in the dopamine case thankfully which is actually cool because it's most most things like the kind of case for pluralism has not always been written out this is okay we'll just go in here but in this this paper they specifically are looking at the meeso cortic olymic dopamine so this is something like what is shown in the um figures in chapter 5 with dopamine controlling the balance between the habit-based policy selection and the expected free energy based policy selection so that's kind of that's the computational function that is being posited in the model that's in the chapter and it's what it's being identified on for um in the table and then this paper's like philosophers biology and saying well people have modeled dopamine in terms of the honia the salience and the reward prediction error basically free energy and they say well there's already evidence to support pluralism for that system but you could make probably analogous Arguments for like every brain region every Gene Etc but that's the whole thing with the maps in the territories it's like okay it's a subway map of this city but it's not an everything map okay okay any other random part of five or one of these questions someone wants to think about sure just to uh to follow up on that last uh question and point really quickly um I think there's a good example this is in an older paper I think it's called um dopamine reward learning and active inference and um it looks at a lot of aspects of like dopaminergic uh function in the brain you know as interpreted through active inference models one one I think is kind of particularly interesting is um freezing of gate in Parkinson's I'm not sure if folks are familiar with that but um long story short people with Parkinson sometimes get this thing where like you get up from a park bench and you try to you know walk across the lawn and and the person will kind of freeze and there haven't been really great explanations about what that's about and like why it happens um but one of the things that I guess uh kind of emerges from this paper if I recall right is the idea that there are basically a bunch of different action policies you know that you can take to navigate the park right you can cross the space in a number of different ways and basically if you have low dopamine levels like people do in Parkinson's then you can have a low potential Precision that's assigned to any one of those given action plans and so with no ability to sort of assign High Precision to one plan or another you have kind of this series of low confid confence plans and the Brain can't kind of like select one on that basis and so you kind of just lock up um and there are like techniques that people with Parkinson's learn to do where they learn to like intentionally choose like okay I'm going to walk in sort of a crescent pattern around this area so they basically like make a different decision that kind of like jolts the system out of um out of the kind of lock state that it gets caught in and you know ultimately I don't know about like are there experimental results that really support this kind of thing I'm not totally sure but I at least I found it to be a really interesting way to think about this kind of thing and I haven't found another um another sort of explanation that I think is is sort of equally as as elegant that's kind of interesting it's like from an that perspective it's like using the brain the brain's plasticity to uh overcome um just erors in its own system as it ages but great yeah comments that just in terms of like research agenda this is like a preliminary stage where you can take the extent data and then make a model that fits the variance patterns better Andor has fewer parameters so it's a better model just by the normal Criterion so that's a computational one and then with that model which can be argued to be like better or simpler than Alternatives it's like well that's the leading candidate to then design experiments that would differentiate and maybe even let the model um show like new predictions or explanations but it's interesting like it's 2015 and it's a very similar figure to figure 4.3 with some more details including about that gamma in the table also this is kind of interesting like without the textbook seven years before the textbook every paper has a lot of the background equations whereas now it's clear which parts are referenceable like to just the textbook and then which parts still might be highlighted in the paper like the focus on the policy and the RO devopment policy yeah interesting paper maybe it's SED in here maybe it's that's this one one or maybe it's another one by the same authors right or no this is only there three of them anyways yeah any other just random thought or or upload questions if you have the Koda up this is kind of like the theor theorizing around like relationship between the fun fun and the anatomy for the brain or the function and the genome like there's kind of a simpler one gene one protein one function or like one anatomical region one Function One computational role but of course that's not how any biological system is so it's kind of a straw hypothesis [Music] to merely disprove because there's so few things that have are with such straightforward causation but those are the interesting ones in some ways but they're also not representative of other cases here's one Mike Len paper to more recent and Josh bongard I'll just copy it in but it kind of talks about like the overloaded nature of the biological systems whereas a computational system you could engineer it to not be overloaded like you could make a which is kind of part of the reason why they don't capture those biological Dynamics because the basing graph like it's just kind of not overloaded among other things thank you Cheryl welcome yeah one book that speaks to um what a little bit of what you describe like the amigdala and the like social events is um this book by Helen Lino about some charged slash relevant topics and how pluralism gets complex but also like very important you know Billboards it's in our DNA and all those kinds of things those are part of the cultural milu that the scientific facts even to the extent that they're empirical factual those are mobilized and that's the whole discussion it and she talks about complex systems and like developmental systems theory as a way to link different scales of analysis so it's kind of like Mike Levan's work like if you you could look at the morphology of organism growing and then over slower time scales you have like structural factors but they're happening at different time scale so neither like the development of the organism or like structural slower factors could explain what the other one does there's there's a lot more I think in that direction that would be awesome to explore on like kind of some of the broader tangents like Oli and that other people bring um up with like very contextual but very rich points about like reductionism and holism free will all these other more psychological things too but also a lot of scientific um epistem slash discussion Susan um yeah you know it's mentioned kind of um offand um in a number of places as far as the um cybernetics and the valuable systems model and yeah I it'd be hard for me to understand uh this if I didn't have a a good understanding of cybernetics um and yeah there's a to to your point um um about it being reductionist Cheryl Cheryl there's uh yeah I you you do kind of hear that in terms of how people are approaching it um and but the same thing I think is is true of cybernetics the original cybernetics was very mechanical um but they've since you know embedded it and Infused it with h with more of a of a Nature's approach so yeah it's it's kind of everything's evolving so you know if we look at it through a static lens we're kind of already GNA be stuck because it's all moving it's all flowing um and that's kind of where we're trying to grasp something but it's flowing away from us and which I think is is fascinating about the topic but I also think that understanding the different levels of ambiguity and abstraction it's hard to you to grasp with that in terms of how do you contain the conversation to go deep when there's so many Avenues to jump on um in fact a question that I had um in terms of Markoff blankets um which uh it might sound like I'm going off on a tangent but there is actually connection is is there in Markoff blankets um what would be the uh the interdependencies how would you how do you describe the interdependencies or are mackoff blankets essentially boundary interdependencies anyone give a thought on that okay one way to think about it maybe narrower or whatever but since the base graph is a causal graph it's a map of determines complexity around what is a determinance but that's how variables determine the influence affect each other that's what the edge on the console graph is so what's there are the determines but what isn't there which is what makes the internal external States separated if they had an edge between them that would be then that would change the shape of the graph another thought related to this is like this this may be a very coarse first approximation but just to to reduce some of it to categories a lot of the questions relate to questions about modeling at all as well as some other very general topics like predicting at all acting at all and then there's also finer scale questions about how active inference formalisms related to like reinforcement learning so th that's those are very different contexts that many people in texbook group are are totally more than Adept at so that's part of the fun also though that may be harder contact shifting but it's also real contact shifting so it's not to be like removed but knowing how to approach more of this like what can numbers and maps have to do with systems at all which is very helpful to have people with some shared background on and then also some will then get to more of a level of resolution of differentiating active inference versus adjacencies in like perceptual control theory reinforcement learning everything that's basically discussed in chapter 10 like from a theory perspective and then also alternative mathematical models for like the mamalian nervous system in chapter 5 because it's easy to be be skeptical and bring up many General points about the models presented in chapter 5 and it's also relevant if one really wants to go into it to contrast not having a model versus not having a model but what are two models for the computational role of dopamine and then which one of those are more plausible and tractable and general and so on but that's a very different discussion than should we make a map of policy selection at all or what could ever be said about a biological organism with math this is like one of those kind of philosophy quotes that that ends up being very influential for a very long time this quote by Kant there will never be Newton of the blade of grass people debited still debate very good discussions very great points and things that I think a lot of people could enter into though very deep within philosophy texts and kind of Niche but this sounds awesome I mean like even just the title of the paper we can read later but I mean this is kind of this is philosophical context for any mathematical work like ACM okay any other part of five or the first part of the book or like any other thoughts or I mean what else I had a question about uh the degree to which their description of uh the math being implemented in the actual neural system uh implies something about like what I would normally think of as modeling assumptions about parametricity um being sort of baked into the mechanics um so in particular right there's like all this focus on uh precision and I understand why that's important um but like in other contexts like there are other statistics later moments that we might care about that like are important to understanding like the shape of a distribution for example um and it normally I'm used to seeing like when when like you know there's an assumption in some paper that like something is gausian uh that that is like a modeling convenience rather than a statement about like a biological reality I I guess when when Precision is like hypothesized to be like an actual thing that's communicated like in in particular systems of the brain does that kind of imply that like particular behaviors can't learn things that are dependent on like the shapes of tales of the distributions that are being communicated about rather than just like their broadness versus or uncertainty around an estimate yeah a lot of great questions in there [Music] um few different pieces there's like this discussion of the support early in the textbook it's kind of like why and then it's it's kind of like what you brought up like but then the Gan goes off to very low so does that mean there's like an infinitely low probability of learning something infinitely rare and like all all these different questions so then like that is the statistical question is like how should it reflect if it's a gaussian situation then that one parameter will do fine capture all the variants but then if it's anything different than that which is basically everything then um and then that also reminds me of um a discussion in this paper or uh SL Liv stream and so here they they were summarizing networks not like just with a mean and variance but summarizing them with more of like a latent space that could be larger um or smaller so it's basically what a variational auto encoder is but they were doing that as like this kind of meta representation it was like it was like very interesting but he shared um but this is basically the tradeoff if you only have two parameters if you only have one parameter to distill the information projected down to then some common choices are like the median the mean arithmetic or geometric mean um or like the waiting time for a single parameter model then with two parameters mean and variance like the measure of central tendency in the first one movement and then the more parameters you have the more expressive you can be but that's the whole question with these large parameter models so you can make and and what uh what riota discussed in in this was actually like and kind of to the Consciousness point was like so the global workspace like the ignition across different sensory modalities so that's the kind of binding of the Consciousness and previously it was studied like does it happen or not or like was the shape perceived or not was the stimuli perceived or not as a kind of conscious to not conscious but then once you're in the space of things that have been perceived then there's a need for richer differentiation because they don't just differ in that one is not the other so then he talked about how you can have richer representations than than all or none another um more statistical answer is uh there's probably a lot of this is you can compose gaussian distributions to approximate any distribution like basically so it's not just two parameters in the actual papers but that's kind of the minimal explainable component like SPM like in the end it's going to result in this map of the brain with statistical with one value per voxel which is like basically the statistical test on whether it's different but there's a ton of parameters up stream of distilling down to one statistic there's very active SPM discussions like they have a mailing list and there's trainings and things like this I don't know if anyone has done the text has done this SPM work but it it may be relevant for the textbook SPM deals less with the action selection and philosophy and more with the statistics sanj's textbook is probably more direct way to learn the statistics specifically however this is still informative statistics just to orient myself SPM is the thing that first made frisan famous yes so SPM is a mat lab toolbox for modeling the functional fmri Dynamic time series data and like including other neural sensors so basically Sensor Fusion in neuroimaging and hence being Mega cited slash being the bread and butter and the method of the priston lab then early in the 2000s this kind of general just take formal approaches to perception cognition action also started to combine with some of the first principles and the physics of cognition and sentience and things like that so this type of a statistical framework is not focused on action on first past it's just modeling observables the sensor data and then the hidden state which is the neural activity so it's like a a matrix and a b Matrix in the textbook no policy selection it just kind of or or it's kind of like um [Music] the chap figure 9.1 like you're viewing the outside so it's like what kind of modeling can you do if all you have is neuroimaging data and behavioral data and information on the people like their you know other details about them and it's very use oriented like all the citations to this let's see SPM SPM 2010 paper being kind of a landmark Fe paper SPM DCM Dynamic caal modeling looking at the the dynamical causal relationships so then like to test whether attention is engaged in a given moment it's like okay well the attentional network connects these nodes and then when it's not attentive it disconnects these nodes and then we're going to test whether this or that model explains this or that behavior very foundational statistical work about like correcting for noise and variance patterns in fmri like slower and faster um noise like Varian and deviations then also first and all have the Clinical Psychology background so then using the mat lab toolkit they have a lot of math papers on the then the toolkit and then also like looking at specific like the stuff that we saw in the table 5.1 with like specific brain regions in specific behaviors and many people who still do fmri mean they use this toolkit let's see the first where AC okay two first active inference firston pulo kind of this is probably similar to the textbook about five years earlier pretty interesting but that's all every field has more papers to read than SL order what to do them in and all of this but it does really emphasize that more of a path-based approach is relevant and also augmented with mega new tools for like processing all of it and so on [Music] Susan yes can you can you say anything about the um the page on active inference model recipe that's pretty cool it's under chapter [Music] six this is kind of their General layout of the book chapter 1 through 5 the epistemic and then chapter 6 through1 the um pragmatic okay that specific page okay yeah there it is this may have been gone through this is just taking the questions that were in the chapter and then that's the ones that are basically just in explained in the subsections okay we also use a language model to ask for more detail on all the sections and then this was um I believe with Michael Carl who later presented some of the work on a stream actually it was very cool about the data set that they had which was related to translators actions like with ey gaze so where they were looking in the text and then what they were typing and deleting and then just doing descriptive statistics like of course you could categorize different categories of translators that would be like you could use a simpler statistical approach or like a deep learning approach because you have the data or and or what does it look like to make an active inference cognitive model that describes the generative process of the translation process which is a complement to the descriptive statistics like generating synthetic data for models that could then be descriptively um describing that output yeah so is this assuming that you there is an observer and an observed or in terms of you know because it's like the question of whoop um you know what must be observed could that be U could that be you know self modeling yeah I'm not GNA know what I'm observing other than what I'm observing if I'm the Observer versus the subject yeah it's it's a very interesting question like definitely s have some private access to certain things but in the case of the Translating like Professor Carl was he it was his laboratory so he knew exactly what the stimuli were they were the observations for the translators the strings of texts and then he knew what measurements the actions of the translator were being observed Obed and this is the kind of like in SPM it was initially with fmri with the MRI imaging time series and then also they're able to combine that with Meg and EEG and and probably other neuroimaging techniques it doesn't even matter what the acronyms are the point is you can have different sensor sets and merge sensor sets with deeper and zeper generative models so if they also had the translators like rate that would be the question okay how do we bring the heart rate in but that doesn't change the affordances but then let's just say also you start looking at their foot tapping then that would be like okay now that's a new affordance to model so that's kind of the interoperability of the active inference models with deep learning some of these models do have multimodal capacities like the ones that can take in text or images and then output like text or images so it's not that other models can't do that it's just there's a lot of other things to say about that like the interpretability or the reliability of adding a new modality all these different features thank you but to make a pedagogical fun exploratory model th those considerations are not going to be hindrances so hence chapter six I think that would be something fun like that's kind of the pacing that we can figure out not necessarily two weeks on six but as as I mean Susan and others no like once we start getting it down in this basically chapter 6 format then we're in feedback with what we have it's easier to communicate it easier to build on it also the technology for applying it given even like this level of detail are far more advanced than they were like one or two or more years ago so it's not like exactly like you could just copy in this little and get a script today but it's not so far away but it wouldn't even matter if it were there would still be going deeper and being more expressive and having in our own generative models more of an understanding and yet also like you can use the GPU and deep learning without knowing all the GPU like Linux kernel details so that's like levels of abstraction in the modeling those are just different experiences somebody wanting to just run the software I mean look at the Port run the software run the kind of fully investigable version understand the minimal unit like understanding the minimal unit of a neural network those kinds of things okay well next week it'll be the last part of this interval coming to this or the other time and then we'll see how people want to um continue six and like also we could explore like how do we want to interact it with seven you know different things we could talk about okay thank you take care everyone 
